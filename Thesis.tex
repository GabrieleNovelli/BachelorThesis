\documentclass[12pt,a4paper]{report}

\usepackage[italian]{babel}
\usepackage{newlfont}
\usepackage{color}
\usepackage{float}
\usepackage{frontespizio}
\usepackage{amsmath,amssymb}
\usepackage{amsthm}
\usepackage{geometry}
\usepackage{tikz}
\usepackage{biblatex}
\usepackage{csquotes}
\usepackage{pgfplots}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{comment}

\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	filecolor=magenta,      
	urlcolor=cyan,
	pdftitle={Overleaf Example},
	pdfpagemode=FullScreen,
}

\textwidth=450pt\oddsidemargin=0pt
\geometry{a4paper, top=3cm, bottom=3cm, left=3cm, right=3cm, % heightrounded, bindingoffset=5mm 
}
\theoremstyle{definition}
\newtheorem{Def}{Definizione}[chapter]

\theoremstyle{Theorem}
\newtheorem{Theo}[Def]{Teorema}
\newtheorem{Prop}[Def]{Proposizione}

\newtheorem{Lm}[Def]{Lemma}

\theoremstyle{definition}
\newtheorem{Ex}[Def]{Esempio}

\theoremstyle{definition}
\newtheorem{Lem}[Def]{Lemma:}

\theoremstyle{definition}
\newtheorem{Obs}[Def]{Osservazione:}





\begin{document}
	\begin{frontespizio}
			\begin{titlepage}
			%
			%
			% UNA VOLTA FATTE LE DOVUTE MODIFICHE SOSTITUIRE "RED" CON "BLACK" NEI COMANDI \textcolor
			%
			%
			\begin{center}
				{{\Large{\textsc{Alma Mater Studiorum $\cdot$ Universit\`a di Bologna}}}} 
				\rule[0.1cm]{15.8cm}{0.1mm}
				\rule[0.5cm]{15.8cm}{0.6mm}
				\\\vspace{3mm}
				
				{\small{\bf Scuola di Scienze \\ 
						Dipartimento di Fisica e Astronomia\\
						Corso di Laurea in Fisica}}
				
			\end{center}
			
			\vspace{23mm}
			
			\begin{center}\textcolor{black}{
					%
					% INSERIRE IL TITOLO DELLA TESI
					%
					{\LARGE{\bf GRUPPI DI LIE E }}
			}\end{center}
		\begin{center}\textcolor{black}{
				%
				% INSERIRE IL TITOLO DELLA TESI
				%
				{\LARGE{\bf RAPPRESENTAZIONI:}}\\
		}\end{center}
	\begin{center}\textcolor{black}{
			%
			% INSERIRE IL TITOLO DELLA TESI
			%
			{\LARGE{\bf LA QUANTIZZAZIONE DEL}}\\
			\vspace{0.25cm}
			{\LARGE{\bf MOMENTO ANGOLARE}}
	}\end{center}
			
			\vspace{50mm} \par \noindent
			
			\begin{minipage}[t]{0.47\textwidth}
				%
				% INSERIRE IL NOME DEL RELATORE CON IL RELATIVO TITOLO DI DOTTORE O PROFESSORE
				%
				{\large{\bf Relatore: \vspace{2mm}\\\textcolor{black}{
							Prof. Rita Fioresi}\\\\
						%
						% INSERIRE IL NOME DEL CORRELATORE CON IL RELATIVO TITOLO DI DOTTORE O PROFESSORE
						%
						% SE NON AVETE UN CORRELATORE CANCELLATE LE PROSSIME 3 RIGHE
						%
						%\textcolor{black}{
							%\bf Correlatore: (eventuale)
						%	\vspace{2mm}\\
						%Prof./Dott. Nome Cognome\\\\}}
					}}
			\end{minipage}
			%
			\hfill
			%
			\begin{minipage}[t]{0.47\textwidth}\raggedleft \textcolor{black}{
					{\large{\bf Presentata da:
							\vspace{2mm}\\
							%
							% INSERIRE IL NOME DEL CANDIDATO
							%
							Gabriele Novelli}}}
			\end{minipage}
			
			\vspace{40mm}
			
			\begin{center}
				%
				% INSERIRE L'ANNO ACCADEMICO
				%
				Anno Accademico \textcolor{black}{ 2022/2023}
			\end{center}
			
		\end{titlepage}
		\end{frontespizio}
	\tableofcontents
	\chapter*{Introduzione}
	In questa tesi introdurremo le nozioni di gruppo di Lie, di rappresentazione di un gruppo e di algebra di Lie, al fine di giustificare la quantizzazione del momento angolare in meccanica quantistica. Il concetto di gruppo si sviluppò a partire da diversi campi della matematica. Per citare solo alcuni dei grandi matematici: nel diciannovesimo secolo, Évariste Galois (1811-1832), al fine di trovare un criterio per la risoluzione delle equazioni polinomiali di grado superiore al 4°, introdusse i gruppi di permutazioni delle soluzioni, denominati poi gruppi di Galois. Nella teoria dei numeri, i primi impieghi del concetto di gruppo risalgono a Carl Friedrich Gauss (1777-1855), nel 1798 e successivamente Leopold Kronecker (1823-
	1891), nel 1850. In ambito geometrico, fu Felix Klein (1849-1925) nel 1872 a servirsi dei gruppi per una riorganizzazione generale delle geometrie non euclidee, aprendo la strada agli studi arrivati successivamente. I concetti di algebra e gruppo di Lie invece risalgono al 1874, ad opera del matematico norvegese Sophus Lie (1842-1899), definiti per studiare i gruppi di trasformazione continui.
	Nel presente lavoro di tesi mostriamo come la teoria dei gruppi e delle algebre di Lie possa essere un valido aiuto nella formalizzazione di alcune teorie fisiche come la quantizzazione del momento angolare.
	\\
	\\
	La tesi è così organizzata:
	nel primo capitolo introdurremo le varietà differenziabili, i campi vettoriali e lo spazio tangente. Questi concetti saranno fondamentali per comprendere ciò che discuteremo nei capitoli successivi.\\
	\\
	Nel secondo capitolo introdurremo i gruppi astratti e di Lie, i rivestimenti e studieremo il rapporto esistente tra un gruppo di Lie e la sua algebra di Lie, definita come l'insieme di tutti i campi vettoriali invarianti a sinistra su questo gruppo. Si vedranno alcuni esempi molto rilevanti per le applicazioni fisiche.\\
	\\
	Nel terzo capitolo definiremo il concetto di rappresentazione di un gruppo di Lie e studieremo le rappresentazioni di $SU_2(\mathbb{C})$ e $SO_3(\mathbb{R})$. Vedremo anche come tra questi insiemi sia definita una corrispondenza 2-1. Sarà proprio questa relazione che ci permetterà di studiare le rappresentazioni di $SO_3(\mathbb{R})$ attraverso quelle di $SU_2(\mathbb{C})$. Dimostreremo inoltre che tutte le rappresentazioni irriducibili dell'algebra di Lie di $SU_2(\mathbb{C})$ hanno una determinata forma.\\
	\\
	Nel quarto capitolo utilizzeremo i risultati trovati in precedenza per studiare le rappresentazioni degli operatori di momento angolare in meccanica quantistica. Otterremo come risultato le celebri relazioni di quantizzazione del momento angolare: $L=l(l+1)\hbar$, $L_z=m_l\hbar$.
	\addcontentsline{toc}{chapter}{Introduzione}
\chapter{Varietà Differenziabili}
In questo capitolo introduciamo le varietà differenziabili, gli spazi tangenti ed i campi vettoriali. Questi concetti verranno utilizzati per lo studio dei gruppi di Lie e teoria della rappresentazione, che vedremo successivamente. Per maggiori dettagli si consulti [1] cap 2.
\section{Varietà differenziabili}
In questa sezione introduciamo la nozione di varietà differenziabile ed alcuni esempi significativi. 

\begin{Def}
	Una \textit{varietà topologica} $M$ di dimensione $n$ è uno spazio topologico di Hausdorff a base numerabile e localmente euclideo di dimensione $n$, cioè per ogni punto $p\in M$ esiste un intorno aperto $U\subset M$ di $p$, e un omeomorfismo $\phi:M\rightarrow\mathbb{R}^n$ da $U$ ad un sottoinsieme aperto di $\mathbb{R}^n$. La coppia $(U,\phi)$ è detta \textit{carta}. Talvolta si dice carta centrata in $p$ o carta in $p$ per evidenziare che $p\in U$. 
\end{Def}
\begin{Ex}
	Lo spazio vettoriale $\mathbb{R}^n$ con la carta $(\mathbb{R}^n, id)$ dove $id:\mathbb{R}^n\rightarrow \mathbb{R}^n$ è l'identità, è una varietà topologica. 
\end{Ex}
\begin{Def}
	Due Carte $(U_1,\phi:U_1\rightarrow\mathbb{R}^n)$ e $(U_2,\varphi:U_2\rightarrow\mathbb{R}^n)$ di una stessa varietà topologica $M$ sono dette \textit{compatibili} se
	$\phi\circ\varphi^{-1}:\varphi(U_1\cap U_2)\rightarrow \phi(U_1\cap U_2)$ e $\varphi\circ\phi^{-1}:\phi(U_1\cap U_2)\rightarrow \varphi(U_1\cap U_2)$ sono $C^\infty$.\\
	Una collezione di carte compatibili $\mathbb{U}=\{(U_i,\phi_{i})\}$ sulla stessa varietà $M$ tali che $M=\bigcup_i U_i$ è detta \textit{atlante}. Una varietà topologica munita di un atlante è detta \textit{varietà differenziabile}.
\end{Def}
Si nota che questa definizione è ben posta in quanto si può mostrare che se due carte sono compatibili con carte dello stesso atlante, allora sono compatibili tra di loro. Per maggiori dettagli si veda [1] (pag. 51, cap. 2).
\begin{Obs}\label{Obs:1.1.1}
Ogni sottoinsieme aperto di una varietà differenziabile è ancora varietà differenziabile. Infatti se $\{(U_i,\phi_i)\}$ è un atlante per $M$, allora considerando $A\subset M$ aperto, la collezione $\{(U_i\cap A,\phi_i|_{U_i\cap A})\}$ è atlante per $A$.
\end{Obs}
Diamo di seguito alcuni esempi di varietà differenziabili:
\begin{Ex}
	Lo spazio $\mathbb{R}^n$ con l'unica carta $(\mathbb{R}^n,\phi)$, dove $\phi=(r^1,...,r^n)$ e $r^i$ sono le coordinate standard di $\mathbb{R}^n$, è una varietà differenziabile. In questo caso un atlante è costituito da un'unica carta. Tuttavia è facile convincersi che ci sono infiniti atlanti con carte compatibili con la carta data in questo esempio.
\end{Ex}
\begin{Ex} \label{Ex 1.1}
	L'insieme $GL_n(\mathbb{R})=\{A\in M_{n\times n}|det(A)\neq0\}$ è una varietà differenziabile.
	Infatti considerando la mappa determinante $det:\mathbb{R}^{n^2}\rightarrow \mathbb{R}$, per definizione $GL_n(\mathbb{R})=det^{-1}(\mathbb{R}-\{0\})$. Poiché che la mappa $det$ è continua, le pre-immagini degli aperti sono aperte, cioè $GL_n(\mathbb{R})$ è un sottoinsieme aperto di $\mathbb{R}^{n^2}$.\\
	Allora, essendo sottoinsieme aperto di una varietà differenziabile, anche $GL_n(\mathbb{R})$ è varietà differenziabile per l'osservazione \ref{Obs:1.1.1}.\\
\end{Ex}
\begin{Ex}
	Si consideri la circonferenza di raggio unitario $S^1=\{x^2+y^2=1\}\subset \mathbb{R}^2$.\\
	Siano le carte $$(U_1=\{x^2+y^2=1;y>0\},\phi_1) \, e \,  (U_2=\{x^2+y^2=1;y<0\},\phi_2)$$ come in Figura 1.1, dove le funzioni di coordinate sono definite come: $\phi_1(x,y)=x$ e $\phi_2(x,y)=x$.
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}
			\draw[->] (-2,0) -- (2,0) node[anchor=north west] {$x$};
			\draw[->] (0,-2.) -- (0,2) node[anchor=south east] {$y$};
			\draw[thick] (0,0) circle (1cm);
			\draw (0.4,1.5) node{$U_1$};
			\draw (-0.4,-1.5) node{$U_2$};
			\draw[thick, ->] (0,1)--(0,0.2) ;
			\draw (0.5,0.5) node{$\phi_1$};
			\draw (-0.5,-0.5) node{$\phi_2$};
			\draw[thick, ->] (0,-1)--(0,-0.2);
		\end{tikzpicture}
	\label{figura 1}
	\caption{le due carte $U_1$ e $U_2$ sulla circonferenza di raggio unitario.}
	\end{figure}
A queste si aggiungano in modo analogo $$(U_3=\{x^2+y^2=1;x>0\},\phi_3)\, e \, (U_4=\{x^2+y^2=1;x<0\},\phi_4)$$ con $\phi_3(x,y)=y$ e $\phi_4(x,y)=y$.\\
Per costruzione, $\phi_i$ è omeomorfismo per ogni $i$. Rimane da verificare che le carte siano tra loro compatibili.\\
Considerando la composizione $\phi_3\circ\phi_2^{-1}$, questa è tale da: $$(\phi_3\circ\phi_2^{-1})(x)=\phi_3(x,-\sqrt{1-x^2})=-\sqrt{1-x^2}$$ per $x\in ]0,1[$, che è $C^\infty$. Per la prova della Compatibilità delle altre carte si procede in modo analogo.\\ 
Dunque abbiamo mostrato che la collezione di carte $(U_i,\phi_i)$ forma un atlante per $S^1$, che dunque è una varietà differenziabile.
\end{Ex}
\begin{Def}
	Un sottoinsieme $S\subset M$ di una varietà $M$ è detto \textit{sottovarietà regolare} di dimensione $k$ se per ogni $p\in M$ esiste una carta $(U,\phi)$ centrata in $p$ tale che $U\cap S$ è definito dall'annullamento di $n-k$ funzioni di coordinate.
\end{Def}
Dunque se $\phi=(x^1,...,x^n)$ allora su $U\cap S$ si avrà $\phi=(x^1,...,x^k,0,0,...0)$.
\begin{Ex}
	Si consideri la varietà differenziabile $\mathbb{R}^n$ e lo spazio $\mathbb{R}^k\subset\mathbb{R}^n$ per $k<n$. Si consideri poi la carta $(\mathbb{R}^n,\phi)=(\mathbb{R}^n,r^1,...,r^n)$ centrata in $p$. Dal fatto che $\mathbb{R}^n\cap \mathbb{R}^k=\mathbb{R}^k$ segue che $\phi|_{\mathbb{R}^k}=(r^1,...,r^k,0,0,...0)$. Questo dimostra che $\mathbb{R}^k$ è una sottovarietà regolare di $\mathbb{R}^n$.
\end{Ex}
\begin{Obs} \label{Obs:1.1.2}
	Nella definizione di sottovarietà regolare, la dimensione di $S$ può coincidere con quella di $M$. In questo caso $U\cap S=U$. Per l'osservazione \ref{Obs:1.1.1}, ogni sottoinsieme $S$ aperto di $M$ è una sottovarietà regolare differenziabile di dimensione uguale a quella di $M$.
\end{Obs}
\section{Mappe differenziabili}
In questa sezione definiamo le mappe differenziabili tra varietà differenziabili e descriviamo alcune loro proprietà importanti. Per maggiori dettagli si veda [1] cap. 2.
\begin{Def}
	Sia una varietà differenziabile $M$ ed una funzione $f:M\rightarrow\mathbb{R}$. Allora $f$ è detta differenziabile di classe $C^\infty$ in $p\in M$ se esiste una carta $(U,\phi)$ centrata in $p$ tale che $f\circ \phi^{-1}$ è $C^\infty$.\\
	La funzione $f:M\rightarrow \mathbb{R}$ è detta differenziabile di classe $C^\infty$ su $M$ se lo è in ogni $p\in M$.
\end{Def}
\begin{Obs}
	La definizione di differenziabilità data non dipende dalla scelta della carta. Infatti se $(U,\phi)$ e $(V,\psi)$ sono due carte di $M$ e $f\circ\phi^{-1}$ è $C^\infty$, allora $$f\circ\psi^{-1}=(f\circ\phi^{-1})\circ(\phi\circ\psi^{-1})$$ che è $C^\infty$.
\end{Obs}
\begin{Obs}
	Se $f:M\rightarrow \mathbb{R}$ è $C^\infty$ allora è continua. Infatti si può scrivere $f=(f\circ\phi^{-1})\circ \phi$ dove $\phi$ e $f\circ\phi^{-1}$ sono continue: $f\circ\phi^{-1}$ è $C^\infty$ e $\phi$ è omeomorfismo. Segue, per composizione di funzioni continue, che $f$ è continua.\\
\end{Obs}
\begin{Def}
	Siano $N$ e $M$ varietà differenziabili di dimensione $n$ ed $m$. Una funzione $f:N\rightarrow M$ continua è detta $C^\infty$ in $p\in N$ se esistono due carte $(U,\phi)$ centrate in $p\in N$ e $(V,\psi)$ centrate in $f(p)\in M$ tali che $\psi\circ f\circ \phi$ è $C^\infty$.
\end{Def}
La composizione ha come dominio $\phi(f^{-1}(V))\cap U$ sottoinsieme di $\mathbb{R}^n$. $$\psi\circ f\circ \phi:\phi(f^{-1}(V)\cap U)\rightarrow \mathbb{R}^m$$.\\
A differenza della definizione precedente, la continuità di $f$ è richiesta per assicurare che la pre-immagine $f^{-1}(V)$ sia un aperto di $N$.\\
\\
Inoltre è possibile dimostrare che la composizione di funzioni $C^\infty$ tra varietà differenziabili è ancora una funzione $C^\infty$ [1] (pag. 62 cap.2). 
\begin{Def}
	Una mappa $f:M\rightarrow N$ tra due varietà si dice \textit{diffeomorfismo} se è biettiva, di classe $C^\infty$ e con inversa di classe $C^\infty$.
\end{Def}
Si può anche dimostrare che tutte le mappe di coordinate di una qualsiasi carta $(U,\phi)$ di una varietà differenziabile sono diffeomorfismi. Per la dimostrazione si veda [1] pag. 63 cap. 2.
\section{Spazio Tangente e Campi Vettoriali}
In questa sezione definiamo lo spazio tangente ed i campi vettoriali, che saranno di vitale importanza nello studio delle algebre di Lie. In tutta questa sezione si indicherà con $M$ una varietà differenziabile generica di dimensione $n$. 
\begin{Def}
	Si considerino tutte le coppie $(f,U)$, dove $U\subset M$ è un intorno di un punto $p\in M$ e $f:U\rightarrow \mathbb{R}$ è una funzione $C^\infty$. Diciamo allora che $(f,U)$ è equivalente a $(g,V)$ se esiste un insieme aperto $W\subset U\cap V$ contenente $p$, tale che $f=g$ quando ristrette a $W$. Si definisce il \textit{germe} di $f$ in $p$ come la classe di equivalenza di $(f,U)$.
	L'insieme di tutti i germi delle funzioni $C^\infty$ in $p\in M$ è indicato con $C^\infty_p(M)$.
\end{Def}
Non è difficile verificare che la relazione così definita è effettivamente di equivalenza: se $f\sim g$ allora $g\sim f$ in quanto le funzioni coincidono in un intorno di $p$. Ovviamente $f\sim f$ e se $f\sim g$, $g\sim h$, allora $f\sim h$ in quanto tutte e 3 le funzioni sono uguali in un intorno di $p$.\\
\\
Generalizzando il concetto di derivazione in $\mathbb{R}^n$, si dice \textit{derivazione} in un punto $p\in M$ una mappa lineare $D_p:C^\infty_p(M)\rightarrow\mathbb{R}$ tale che $$D_p(fg)=D_p(f)g(p)+f(p)D_p(g)$$
Cioè rispetta la regola di Leibniz.
\begin{Def}
	Una derivazione in $p\in M$ è detta vettore tangente in $p$. L'insieme di tutti i vettori tangenti in $p$ è detto \textit{spazio tangente} e si indica con $T_pM$.
\end{Def} 
Data una Carta $(U,\phi)$ di $M$ centrata in $p\in M$, si pone:
$${\partial\over \partial x^i}\bigg\rvert_p(f)={\partial\over \partial r^i}\bigg\rvert_{\phi(p)}(f\circ \phi^{-1})$$ dove $r^i$ sono le coordinate di $\mathbb{R}^n$.
Questa definizione rende ${\partial\over \partial x^i}$ un campo vettoriale in quanto rispetta la regola di Leibniz.\\
\\
Un importante risultato è che, dato uno spazio tangente $T_pM$ e una carta $(U,\phi)$ centrata in $p$, allora i vettori $\partial\over \partial x^i$ formano una base per $T_pM$. Ciò deriva dal fatto che i vettori tangenti $\partial\over \partial r^i$ sono una base per lo spazio tangente in $x_0\in\mathbb{R}^n$, che ha dimensione uguale a quella della verietà $M$.\\
Dunque un generico vettore tangente può essere espresso come una combinazione lineare: $$\vec{v}=\sum_{i=1}^{n}c_i{\partial\over \partial x^i}$$ che dipende dal punto interno alla carta. 
\begin{Obs} \label{Obs 1.1.3}
	Preso il sottoinsieme aperto $GL_n(\mathbb{R})$ di $M_{n\times n}$, per le osservazioni \ref{Obs:1.1.1} e \ref{Obs:1.1.2}, $GL_n(\mathbb{R})$ è una sottovarietà differenziabile di $M_{n\times n}$ e la sua dimensione è $n^2$, uguale a quella di $M_{n\times n}$. Ma lo spazio tangente nell'identità $T_\mathbb{I}M_{n\times n}$ ha anche esso dimensione $n^2$. Da ciò, $T_\mathbb{I}GL_n(\mathbb{R})=T_\mathbb{I}M_{n\times n}$.
\end{Obs}
\begin{Def}
	Data una funzione $C^\infty$ tra varietà differenziabili $F:N\rightarrow M$, si dice \textit{differenziale} in un punto $p\in N$ la mappa $dF_p:T_pN\rightarrow T_{F(p)}M$ definita come segue: dato il vettore $X_p\in T_pN$ e la funzione $f\in C_{F(p)}^\infty(M)$, allora $dF_p(X_p)f=\\X_p(f\circ F)\in\mathbb{R}$.
\end{Def}
Dalla linearità dei vettori tangenti e dal fatto che essi sono derivazioni, segue che il differenziale è una derivazione ed è lineare. \\
E' possibile dimostrare che per il differenziale di una funzione composta vale la regola della catena: $$d(F\circ G)_p=dF_{G(p)}\circ dG_p$$ Per la dimostrazione si veda [1] (pag. 88 cap 3).
\begin{Ex}
	Siano $x^1,...,x^n$ le coordinate di $\mathbb{R}^n$ e le $y^1,...,y^m$ le coordiante di $\mathbb{R}^m$. Sia una mappa $F:\mathbb{R}^n\rightarrow \mathbb{R}^m$ di classe $C^\infty$ e sia $p\in \mathbb{R}^n$. Allora il differenziale di $F$ calcolato in $p$ è una mappa $dF_p:T_p\mathbb{R}^n\rightarrow T_{F(p)}\mathbb{R}^m$ tale che, presi un generico vettore $X_p\in T_p\mathbb{R}^n$ ed una funzione $f\in C_{F(p)}^\infty(\mathbb{R}^m)$, vale la relazione $dF_p(X_p)f=X_p(f\circ F)$.\\
	Ricordando che una base di $T_p\mathbb{R}^n$ è costituita dai vettori $\{{\partial\over\partial x^i}\}$, allora preso vettore $X_p\in T_p\mathbb{R}^n$ definito come $X_p={\partial\over \partial x^j}$, avremo $$dF_p\bigg{(}{\partial\over \partial x^j}\bigg{)}=\sum_{k=1}^{m}d_j^k{\partial\over \partial y^k}\bigg{\rvert}_p$$
	I coefficienti $d$ si possono trovare valutando 
	$$dF_p\bigg{(}{\partial\over \partial x^j}\bigg{)}y^i=\sum_{k=1}^{m}d_j^k{\partial\over \partial y^k}\bigg{\rvert}_{F(p)}y^i=d_j^i$$
	Inoltre, sapendo che, per definizione di differenziale, vale la relazione $dF_p(X_p)f=X_p(f\circ F)$, è possibile trovare un'espressione per i coefficienti $d_j^i$:
	$$dF_p\bigg{(}{\partial\over \partial x^j}\bigg{)}y^i={\partial\over \partial x^j}\bigg{\rvert}_p(y^i\circ F)={\partial F^i\over \partial x^j}(p)=d^i_j$$
	Quindi la matrice che definisce il differenziale di $F$ in un punto $p$ è esattamente la matrice Jacobiana delle derivate di $F$ calcolate nel punto $p$.
\end{Ex}
Veniamo ora al concetto di campo vettoriale, definito come una mappa che ad ogni punto associa un vettore.
\begin{Def}
	Si dice \textit{campo vettoriale} su $M$ una mappa $X$ tale che ad ogni punto associa un vettore nello spazio tangente al punto stesso: $X:p\mapsto X_p$. 
\end{Def}
\begin{Obs}
	Abbiamo visto che un vettore può essere identificato come una mappa $\vec{v}:f\mapsto\sum_{i=1}^{n}c_i{\partial f\over \partial x^i}$ per un generico punto interno ad una data carta. Allora un campo vettoriale può essere visto anche come un'applicazione $X:f\mapsto\vec{v}(f)$ tale che $X(f)(p)=\sum_{i=1}^{n}c_i(p){\partial f(p)\over \partial x^i}$
\end{Obs}
\begin{Def}
	Un campo vettoriale $X$ su $M$ si dice \textit{liscio} o $C^\infty$ se per ogni $f\in C^\infty(M)$ si ha che $X(f)$ è ancora $C^\infty$.
\\
Equivalentemente, $X=\sum_{i=1}^{n}c_i{\partial\over \partial x^i}$ è detto $C^\infty$ se le funzioni $c_i$ sono tutte $C^\infty$.
\begin{Def}
	Una curva $c_p:]-\epsilon,\epsilon[\rightarrow M$ è detta \textit{curva integrale} di un campo vettoriale $X$ su $M$ passante per $p\in M$ se $c_p(0)=p$ e $c_p'(0)=X_p$.
\end{Def}
Dalla teoria delle equazioni differenziali, dato un punto $p\in M$ ed un campo vettoriale $X$ definito in un intorno di $p$, esiste sempre una curva integrale di $X$ in $p$ ed è unica. Per approfondire questo risultato si veda [1] pag. 154 cap.3.\\
\\
E'utile definire il concetto di flusso di un campo vettoriale $X$ come una mappa $\Phi_X:\mathbb{R}\times M\rightarrow\mathbb{M}$ tale che $\Phi_X(0,p)=p$; $\Phi_X(t,p)=c_p(t)$ curva integrale di $X$.\\
\\
Vi sono numerose proprietà del flusso di un campo vettoriale. Per approfondimenti in materia si veda [1] pag. 155, 156 cap. 3.
\end{Def}
\chapter{Gruppi e algebre di Lie} \label{Chap: 2}
In questo capitolo introduciamo i gruppi topologici e di Lie, i rivestimenti, la mappa esponenziale, e le algebre di Lie. Come vedremo, questi strumenti saranno utilizzati per lo studio delle rappresentazioni dei gruppi di Lie. Per approfondimenti in materia si consultino: [2] pag. 41-84 cap. 2; [4] parte 1, cap. 1-4 ; [5] pag. 27-38 cap. 5; pag. 143-150 cap. 17.
\section{Gruppi Topologici e azioni di gruppi} \label{Sec:2.1}
In questa sezione diamo la definizione di gruppo topologico e introduciamo i quozienti di gruppi e le azioni di gruppi.
\begin{Def}
	Si dice \textit{gruppo} un insieme $G$ munito di un'operazione binaria $\cdot:G\times G\rightarrow G$ detta \textit{moltiplicazione} tale che:
	\begin{itemize}
		\item Associatività: $a\cdot (b\cdot c)=(a\cdot b)\cdot c$ $\forall a,b,c\in G$;
		\item Esistenza dell'elemento neutro: $\exists e\in G$ tale che $\forall a\in G$ si ha $a\cdot e=e\cdot a=a$;
		\item Esistenza dell'inverso: $\forall a\in G$ $\exists a^{-1}$ tale che $a\cdot a^{-1}=a^{-1}\cdot a=e$.
	\end{itemize}
	Un gruppo la cui operazione soddisfa anche la proprietà commutativa, cioè $ab= b\cdot a$ per ogni $a,b\in G$, è detto abeliano o commutativo.
\end{Def}
Da ora in avanti, quando si farà riferimento all'operazione di prodotto definita per un gruppo, si ometterà il simbolo $\cdot$.
\begin{Def}
	Un \textit{gruppo di topologico} $G$ è uno spazio topologico con la struttura di gruppo, tale che le operazioni di moltiplicazione $\cdot:G\times G\rightarrow G$ e inversione $i:G\rightarrow G$ tale che $i(g)=g^{-1}$ sono continue.
\end{Def}
\begin{Ex}
	Lo spazio $\mathbb{R}$ con la topologia euclidea è l'operazione di addizione è un gruppo topologico abeliano.
\end{Ex}
Definiamo ora il concetto di azione di gruppo su un generico insieme $X$.
\begin{Def}
	Dato un gruppo $G$ ed un insieme $X$, si dice che $G$ \textit{agisce} (da sinistra) su $X$ o che $X$ è un \textit{$G$ insieme} (sinistro) se esiste una mappa, detta \textit{azione} (sinistra) $a:G\times X\rightarrow X$ tale che:
	\begin{itemize}
		\item 	$a(e,x)=x$ per ogni $x\in X$;
		\item $a(gh,x)=a(g,a(h,x))$ per ogni $g,h\in G$ e $x\in X$.
	\end{itemize} 
Nel caso $X$ sia anche spazio topologico, se la mappa $x\longmapsto a(g,x)$ è continua per ogni $g\in G$, allora $X$ è chiamato \textit{$G$ spazio}.
Denoteremo $a(g,x)$ anche come $g\cdot x$.
\end{Def}
\begin{Obs}
Abbiamo definito il concetto di azione $\textit{sinistra}$, tuttavia avremmo potuto definire un'azione destra: $b:X\times G\rightarrow X$ tale che $b(x,e)=x$ e $b(x,gh)=b(b(x,g),h)$. Possiamo mostrare con un rapido calcolo che, data un'azione sinistra, è automaticamente definita un'azione destra: infatti, data $a:G\times X\rightarrow X$ definita come $(g,x)\longmapsto a(g,x)$, si può costruire una mappa $b:X\times G\rightarrow X$ definita come $(x,g)\longmapsto a(g^{-1},x)=b(x,g)$. Non è difficile verificare che questa nuova azione rispetta le proprietà richieste:
$$b(x,e)=a(e,x)=x$$
In quanto $e^{-1}=e$ dato che $G$ è un gruppo. Ricordando poi che $(gh)^{-1}=h^{-1}g^{-1}$, si ha la catena di uguaglianze:
$$b(x,gh)=a((gh)^{-1},x)=a(h^{-1}g^{-1},x)=$$$$=a(h^{-1},a(g^{-1},x))=a(h^{-1},b(x,g))=b(b(x,g),h)$$
Questo dimostra che la mappa destra $(x,g)\longmapsto a(g^{-1},x)$ è ben definita.\\
Da ora in avanti quando parleremo di azioni intenderemo azioni sinistre.
\end{Obs}
Diamo ora la definizione di orbita di un punto appartenente ad un $G$ insieme.
\begin{Def}
	Sia $X$ un $G$ insieme e $x\in X$. L'insieme $O_x=\{a(g,x); \, \forall g\in G\}$ è detto \textit{orbita} di $x\in X$. Si definisce $\textit{stabilizzatore}$ di $x\in X$ l'insieme $G_x=\{g\in G|a(g,x)=x\}$. A volte indicheremo lo stabilizzatore di un punto $x$ anche con $Stab_x$.
\end{Def}
\begin{Obs} \label{Obs: 2.1}
	Si può facilmente verificare che due orbite o sono uguali o sono disgiunte. Infatti, presi $O_x$ e $O_y$ orbite, e un punto $z\in O_x\cap O_y$, possiamo scrivere:
	$$z=a(g,x)=a(g',y)$$
	Ma allora $x=a(g^{-1}g',y)$, cioè le orbite coincidono.
	Da questo segue che $X$ è unione disgiunta delle orbite dei suoi punti: $X=\bigsqcup O_x$.
\end{Obs}
\begin{Def}
	Un'azione di un gruppo $G$ su di un insieme $X$ è detta \textit{transitiva} se esiste un'unica orbita, ovvero se per ogni $x,y\in X$ esiste $g\in G$ tale che $x=a(g,y)$.
\end{Def}
Vediamo ora qualche esempio:
\begin{Ex} [Azione di $SL_2(\mathbb{R})$ su $\mathbb{R}^2$]
	Consideriamo il gruppo $SL_2(\mathbb{R})=\{A\in M_{2\times 2}\,|\,det(A)=1\}$ e lo spazio $\mathbb{R}^2$. Definiamo l'azione $a:SL_2(\mathbb{R})\times \mathbb{R}^2\rightarrow\mathbb{R}^2$ come 
	$$a(A,(x,y))=A\begin{pmatrix}
		x\\y
	\end{pmatrix}$$
dove $A\in SL_2(\mathbb{R})$ e $(x,y)\in\mathbb{R}^2$. Non è difficile verificare che la mappa così definita rispetta tutte le proprietà di un'azione. Procediamo ora al calcolo delle orbite di $(0,0)$, $(1,0)$ e mostriamo che questa stessa azione, ristretta a $\mathbb{R}^2\setminus\{(0,0)\}$, è transitiva.
L'orbita di $(0,0)$ è il solo punto $(0,0)$:
$$A\begin{pmatrix}
	0\\0
\end{pmatrix}=\begin{pmatrix}
0\\0
\end{pmatrix}$$
per ogni $A\in SU_2(\mathbb{R})$. Calcoliamo l'orbita di $(1,0)$:
$$A\begin{pmatrix}
	1\\0
\end{pmatrix}=\begin{pmatrix}
a&c\\
b&d
\end{pmatrix}\begin{pmatrix}
1\\0
\end{pmatrix}=\begin{pmatrix}
a\\b
\end{pmatrix}$$
Con $a\neq 0$ o $b\neq 0$ in quanto è necessario che $ad-bc=1$ per la condizione $det(A)=1$. Abbiamo trovato $$O_{(1,0)}=\{(a,b);\, a,b\in\mathbb{R}\,\, \hbox{tali che} \, \, a \neq 0 \, \hbox{oppure} \, b\neq 0 \}$$ 
Questo significa che ogni punto di $\mathbb{R}^2-\{(0,0)\}$ appartiene all'orbita di $(1,0)$, cioè l'azione di $SL_2(\mathbb{R})$ su $\mathbb{R}^2-\{(0,0)\}$ è transitiva.
Riprendendo l'osservazione \ref{Obs: 2.1}, notiamo che lo spazio $\mathbb{R}^2$ è unione disgiunta delle orbite di $(1,0)$ e di $(0,0)$.
E' anche possibile calcolare lo stabilizzatore di $(1,0)$:
$$\begin{pmatrix}
	a&c\\
	b&d
\end{pmatrix}\begin{pmatrix}
1\\0
\end{pmatrix}=\begin{pmatrix}
a\\b
\end{pmatrix}=\begin{pmatrix}
1\\0
\end{pmatrix}$$
che è verificato solamente se $a=1$ e $b=0$. La condizione sul determinante impone inoltre che $ad-bc=1$, da cui $a=1/d=1$.
$$Stab_{(1,0)}=\bigg{\{}\begin{pmatrix}
	1&c\\
	0&1
\end{pmatrix}\bigg{\}}$$
\end{Ex}
\begin{Theo}
	Dato un $G$ insieme $X$ e la mappa $\theta_g:X\rightarrow X$ tale che $\theta_g(x)=a(g,x)$, allora $\theta_g$ è biettiva per ogni $g$.
\end{Theo}
\begin{proof}
	Per costruzione: $\theta_g^{-1}=\theta_{g^{-1}}$, inoltre $\theta_g\theta_{g^{-1}}=id=\theta_{g^{-1}}\theta_g$ da cui il risultato.
\end{proof}
\begin{Obs}
	Per definizione, se $X$ è $G$ spazio, allora $\theta_g$ è un omeomorfismo, in quanto continua, invertibile e con inversa continua.
\end{Obs}
\begin{Obs}
	Dato un $G$ spazio indicato con $X$, si può definire una relazione di equivalenza $\sim$ come: $x\sim y$ se e solo se $y\in O_x$, cioè se esiste $g\in G$ tale che $a(g,x)=y$. Questa relazione è  di equivalenza e l'insieme di tutte le classi di equivalenza si indica con $X/G$. Se $G$ è uno spazio topologico, è possibile dare a $X/G$ la topologia quoziente. 
	L'orbita $O_x$ di un generico punto corrisponde alla classe laterale $G\cdot x$, cioè tutti gli elementi ottenibili attraverso la moltiplicazione (azione) di un elemento di $G$ per $x$. \\
	Allo stesso modo, dato $U\subset X$ con $g\cdot U$ si indicano tutti gli elementi di $X$ ottenibili attraverso la moltiplicazione (azione) di $g$ con un generico elemento di $U\subset X$. 
\end{Obs}
\begin{Theo}
	Se $X$ è un $G$ spazio, allora la mappa $\pi:X\rightarrow X/G$ definita come $\pi(x)=O_x$ è aperta.
\end{Theo}
\begin{proof}
	Per vedere che $\pi$ è aperta, dobbiamo verificare che $\pi(U)$ è aperto se $U$ è aperto. Allora, preso un generico $U\subset X$ aperto in $X$, abbiamo:
	$$\pi^{-1}(\pi(U))=\{x\in X \,|\, \pi(x)\in \pi(U)\}=\{x\in X \,|\, O_x=O_y \,\hbox{per un} \, y\in U\}=$$
	$$=\{x\in X \, | \, x=a(g,y) \, \hbox{per} \, g\in G, y\in U\}=$$
	$$=\{x\in X \, | \, x=g\cdot U \, \hbox{per} \, g\in G\}= \bigcup_{g\in G} g\cdot U=\bigcup_{g\in G}\theta_g(U)$$
	Inoltre, $\theta_g$ è un omeomorfismo in quanto $X$ è un $G$ spazio. Ma allora $\theta_g$ manda aperti in aperti, cioè se $U$ è aperto, anche $\theta_g(U)$ è aperto e quindi $\pi^{-1}(\pi(U))$ è aperto in quanto unione di aperti. Ma allora, per definizione di topologia quoziente, $\pi(U)$ è aperto.
\end{proof}
\section{Rivestimenti}
In questa sezione introdurremo i rivestimenti di uno spazio topologico ed alcuni risultati inerenti ad essi. Ciò che sarà discusso in questa sezione verrà poi utilizzato nell'analisi del gruppo $SO_3(\mathbb{R})$. Per maggiori dettagli si veda [5] cap 17.
\begin{Def} \label{Def: 2.2.2}
	Dati due spazi topologici $X$ e $\tilde{X}$ ed una mappa continua $p:\tilde{X}\rightarrow X$, allora $p$ è detta \textit{rivestimento} se:
	\begin{itemize}
		\item $p$ è suriettiva;
		\item per ogni $x\in X$ esiste $U\subset X$ intorno di $x$ tale che $p^{-1}(U)=\bigsqcup_j V_j$. Dove $\{V_j\}$ è una collezione di sottoinsiemi aperti di $\tilde{X}$ disgiunti a due a due e tale che, per ogni $j$, $p\rvert_{V_j}:V_j\rightarrow U$ è omeomorfismo. 
	\end{itemize}
\end{Def}
	Dato uno spazio topologico $X$, si definisce \textit{rivestimento banale} la mappa $p:X\rightarrow X$ definita come $p(x)=x$. Ovviamente $p$ così definita verifica tutte le proprietà in quanto identità.
\begin{Ex}
	Si consideri lo spazio topologico $S^1$ definito come il cerchio di raggio unitario. Allora la mappa $p:\mathbb{R}\rightarrow S^1$ tale che $p(t)=e^{it}$ è un rivestimento di $S^1$. Per ogni punto è possibile trovare un arco aperto $V$ che lo contiene, tale che $p^{-1}(V)$ è unione disgiunta di intervalli aperti.
\end{Ex}
\begin{center}
\begin{tikzpicture}
	\begin{axis}[axis lines=none, zmax=13, zmin=-10.2 ]
		\addplot3[domain=0:5*pi,
		samples = 100,
		samples y=0,
		]
		({sin(deg(x))},
		{cos(deg(x))},
		{-10});
		\addplot3[
		domain=0:5*pi,
		samples = 100,
		samples y=0,
		]
		({sin(deg(x))},
		{cos(deg(x))},
		{x});
		\addplot3[
		domain=pi:1.2*pi,
		samples = 100,
		samples y=0,
		ultra thick
		]
		({sin(deg(x))},
		{cos(deg(x))},
		{x});
		\addplot3[
		domain=3*pi:3.2*pi,
		samples = 100,
		samples y=0,
		ultra thick
		]
		({sin(deg(x))},
		{cos(deg(x))},
		{x});
		\addplot3[
		domain=pi:1.2*pi,
		samples = 100,
		samples y=0,
		ultra thick
		]
		({sin(deg(x))},
		{cos(deg(x))},
		{-10});
	\end{axis}
\node at (1.3,1) {$V$};
\node at (5.3,1) {$S^1$};
\node at (6.3,4) {$\mathbb{R}$};
\node at (0.2,3.1) {$p^{-1}(V)$};
\draw[->] (2.5,2)--(2.5,1) node[anchor=south east] {$p$};
\end{tikzpicture}
	
\end{center}
\begin{Theo}
	Se $p:\tilde{X}\rightarrow X$ è un rivestimento, allora $p$ è una mappa aperta e $X$ ha la topologia quoziente rispetto ad $\tilde{X}$.
\end{Theo}
\begin{proof}
	Sia $U$
 un insieme aperto di $\tilde{X}$ e sia $x\in p(U)$. Allora, dato che $p$ è un rivestimento, esiste un intorno $V\subset X$ di $x$ tale che $p^{-1}(V)=\bigcup_jA_j$ dove $\{A_j\}$ è una collezione di aperti in $\tilde{X}$. Sia allora un punto $\tilde{x}\in p^{-1}(x)\cap U$. Dato che $\tilde{x}\in p^{-1}(V)$ per definizione, esiste un $A_j\subset \tilde{X}$ aperto tale per cui $\tilde{x}\in A_j$. Essendo $A_j\cap U$ aperto in quanto intersezione di aperti ed essendo $p|_{A_j}:A_j\rightarrow V$ un omeomorfismo, allora $p(A_j\cap U)$ è un sottoinsieme aperto di $V$ e quindi anche di $X$. Per arbitrarietà di $x$ scelto, $p(U)$ è aperto.\\
 \\
 Per la seconda parte del teorema si vede che $p$ è una mappa aperta continua: preso $V\subset X$, esso è aperto se e solo se $p^{-1}(V)$ è aperto in $\tilde{X}$.  
\end{proof}
\begin{Def} \label{Def:2.2.1}
	Se $p:\tilde{X}\rightarrow X$ è un rivestimento e $\tilde{X}$ è semplicemente connesso, allora $p$ è detto rivestimento universale.
\end{Def}
\begin{Obs}
	Per quanto riguarda l'esistenza del rivestimento universale di un determinato spazio topologico $X$, è possibile dimostrare che se $X$ è connesso e semplicemente connesso allora esso possiede un rivestimento universale. Per approfondimenti a riguardo si veda [5] cap. 22.
\end{Obs}
\section{Gruppi di Lie}
In questa sezione daremo la definizione di gruppo e sottogruppo di Lie, con alcuni esempi ed importanti risultati. Per maggiori dettagli si consulti [1] pag. 164-174 cap. 4 e [3] cap 1.
\begin{Def}
	Un \textit{gruppo di Lie} $G$ è una varietà differenziabile con la struttura di gruppo, tale che le operazioni di moltiplicazione $\cdot:G\times G\rightarrow G$ e inversione $i:G\rightarrow G$ sono $C^\infty$.
	Un \textit{sottogruppo} $H$ di un gruppo di Lie $G$ è una sottovarietà regolare di $G$ che è ancora gruppo con l'operazione indotta da $G$.
\end{Def}
\begin{Ex}
	Si consideri $GL_n(\mathbb{R})$, che si è provato essere varietà differenziabile. Date le operazioni prodotto righe per colonne e $i$ inverso di una matrice, queste rendono $GL_n(\mathbb{R})$ un gruppo. Infatti il prodotto righe per colonne è associativo ed ha $\mathbb{I}$ come elemento neutro, mentre l'esistenza dell'inverso è garantita dalla condizione $det\neq 0$. Il fatto che queste due operazioni siano $C^\infty$ rende $GL_n(\mathbb{R})$ un gruppo di Lie.
\end{Ex}
\begin{Ex}
	Si consideri $SL_n(\mathbb{R})=\{A\in M_{n\times n}| det(A)=1\}$. Dal fatto che $SL_n(\mathbb{R})=det^{-1}(1)$ segue che $SL_n(\mathbb{R})$ è un sottogruppo chiuso di $GL_n(\mathbb{R})$. Inoltre è possibile dimostrare ([1] pag. 105 cap. 3, Teorema 9.9) che $SL_n(\mathbb{R})$ è una sottovarietà regolare di $GL_n(\mathbb{R})$ di dimensione $n^2-1$. Dato che le operazioni di moltiplicazione e inversione $i$ sono ancora $C^\infty$ su $SL_n(\mathbb{R})$, questo gruppo è un sottogruppo di Lie di $GL_n(\mathbb{R})$.\\
	\\
	Per approfondire questo esempio di veda [1] pag. 105-107, 125, 165 cap. 3 e 4.\\
	\\
	E' possibile dimostrare che (indicando con $^+$ l'operazione di aggiunzione e con $T$ quella di trasposizione):\\\\
	$O_n(\mathbb{R})=\{A\in M_{n\times n}(\mathbb{R})\, |\, A^TA=AA^T=\mathbb{I}\};$\\\\
	$SO_n(\mathbb{R})=\{A\in M_{n\times n}(\mathbb{R})\, |\, A^TA=AA^T=\mathbb{I};\, det(A)=1\};$\\\\
	$U_n(\mathbb{R})=\{A\in M_{n\times n}(\mathbb{R})\, |\, A^+A=AA^+=\mathbb{I}\};$\\\\
	$SU_n(\mathbb{R})=\{A\in M_{n\times n}(\mathbb{R})\, |\, A^+A=AA^+=\mathbb{I};\,det(A)=1\};$\\\\
	sono tutti gruppi di Lie reali (risp. complessi). 
	Per le dimostrazioni di veda [2] pag. 41-51 cap. 2.
\end{Ex}

\begin{Def}
	Si dice \textit{omomorfismo tra gruppi di Lie} $G$ e $H$ una mappa \\$f:G\rightarrow H$ di classe $C^\infty$ tale che $f(gh)=f(g)f(h)$.
\end{Def}
Notiamo che un omomorfismo tra gruppi manda sempre l'identità nell'identità. Infatti $f(eg)=f(e)f(g)$ ed $f(g)=f(eg)$.\\\\
Si indica con $l_g:G\rightarrow G$ dove $l_g(x)=gx$ l'operazione di moltiplicazione a sinistra su $G$ gruppo di Lie.
\begin{Obs}
	$l_g$ è $C^\infty$ in quanto è definita come moltiplicazione su di un gruppo di Lie. Da ciò segue che $l_g$ è anche continua. Inoltre $l_g^{-1}=l_{g^{-1}}$ che è ancora continua e di classe $C^\infty$. Quindi $l_g$ è un diffeomorfismo.
\end{Obs}
\section{Algebre di Lie}
In questa sezione introduciamo la definizione di algebra di Lie generica e di campo vettoriale invariante a sinistra, con alcuni esempi. Per maggiori dettagli si veda [1] cap. 4, [2] cap. 2 pag. 46.
\begin{Def}
	Si dice \textit{algebra di Lie reale} (risp. complessa) uno spazio vettoriale reale $\mathfrak{g}$ (risp. complesso) in cui è definita un'operazione binaria bilineare (detta Lie bracket) $[,]:\mathfrak{g}\times\mathfrak{g}\rightarrow\mathfrak{g}$ tale che verifica:
	\begin{itemize}
		\item Antisimmetria: $[x,y]=-[y,x]$, $\forall x,y\in\mathfrak{g}$;
		\item Identità di Jacobi: $[x,[y,z]]+[y,[z,x]]+[z,[x,y]]=0$, $\forall x,y,z\in \mathfrak{g}$ 
	\end{itemize}
	Si dice \textit{sottoalgebra} di Lie di $\mathfrak{g}$ un sottospazio vettoriale $\mathfrak{h}\subset\mathfrak{g}$ chiuso rispetto all'operazione $[,]$ di $\mathfrak{g}$.\\
		Si definisce un \textit{omomorfismo tra algebre di Lie} una mappa lineare $f:\mathfrak{g}\rightarrow\mathfrak{h}$ tale che $f([x,y])=[f(x),f(y)]$ per ogni $x,y\in\mathfrak{g}$.
\end{Def}
Salvo specificazioni, le algebre di Lie considerate saranno sottintese a dimensione finita.
\begin{Obs}
	L'identità di Jacobi implica in generale la non associatività del prodotto $[,]$. Se infatti questo fosse associativo, si avrebbe $[x,[y,z]]=[[x,y],z]$.
\end{Obs}
\begin{Ex} \label{Obs: bracket Mnn}
	Consideriamo lo spazio $M_{n\times n}(\mathbb{R})$ di tutte le matrici sul campo $\mathbb{R}$. Definiamo un bracket in questo modo: prese due matrici $A$ e $B$ appartenenti ad $M_{n\times n}(\mathbb{R})$, $[A,B]=AB-BA$. In questo modo $[,]$ è automaticamente bilineare ed anticommutativo, mentre l'identità di Jacobi si prova sviluppando l'espressione:
	$$[A,[B,C]]+[B,[C,A]]+[C,[A,B]]=$$
	$$=[A,BC-CB]+[B,CA-AC]+[C,AB-BA]=$$
	$$=ABC-ACB-BCA+CBA+BCA-BAC-CAB+ACB+$$
	$$+CAB-CBA-ABC+BAC=0$$
	Abbiamo provato che $[,]$ definito in questo modo rende $M_{n\times n}(\mathbb{R})$ un'algebra di Lie.
\end{Ex}
\begin{Ex}
	Sia un generico spazio vettoriale $V$ su $\mathbb{R}$. Allora definendo la Lie bracket come $[,]:V\times V\rightarrow V$ tale che $[x,y]=0$, $V$ diviene algebra di Lie.\\
	Infatti la linearità e l'anticommutatività sono rispettate e l'identità di Jacobi si riduce a $0+0+0=0$.
\end{Ex}
\begin{Def}
	Un campo vettoriale $X$ su un gruppo di Lie $G$ si dice \textit{invariante a sinistra} se $dl_g(X)=X$ per ogni $g\in G$.
\end{Def}
Un campo vettoriale è invariante a sinistra se la sua traslazione con l'operazione indotta dalla moltiplicazione lo lascia invariato: cioè se $dl_g(X_h)=X_{gh}$ per ogni $g,h\in G$.
Ne consegue che $X_g=dl_g(X_e)$, ovvero che un campo vettoriale invariante a sinistra è completamente determinato dal suo valore all'identità del gruppo.\\
\\
E' possibile dimostrare che ogni campo $X$ invariante a sinistra su di un gruppo di Lie è $C^\infty$. ([1] pag. 181 cap.4).
\section{Algebra di Lie di un gruppo di Lie}
In questa sezione diamo la definizione di algebra di Lie di un gruppo di Lie. Enunceremo inoltre alcuni risultati che ci permetteranno di identificare l'algebra di Lie di un gruppo di Lie con il suo spazio tangente nell'identità. Per maggiori dettagli si veda [1] pag 178-182 cap.4, [3] cap. 1 e [4] parte 1 cap.3.
\begin{Obs} \label{Obs: 2.2}
	Dato un gruppo di Lie $G$ ed un vettore $A\in T_eG$ tangente nell'identità, si può definire un campo vettoriale $X^A:G\rightarrow T_eG$ ponendo $X^A_g=dl_g(A)$. Questo campo è invariante a sinistra in quanto: $$dl_g(X^A_h)=dl_g(dl_h(X^A_e))=dl_{gh}(X^A_e)=dl_{gh}(A)=X^A_{gh}$$
	In questo caso diciamo che $X^A$ è generato da $A\in T_eG$ e chiamiamo $Lie(G)$ l'insieme di tutti gli $X^A$ generati dai vettori tangenti nell'identità in $G$.	
\end{Obs}
Dati due campi vettoriali $X$ e $Y$, definiamo la loro Lie Bracket in un punto $p$:
 $$[X,Y]_pf=(X_pY-Y_pX)f$$
E' possibile dimostrare che se $X$ e $Y$ sono campi vettoriali lisci su $M$, allora anche $[X,Y]$ è liscio su $M$. Per dettagli sulla dimostrazione si veda [1] pag. 157 cap. 4.
Vale inoltre il seguente risultato:
\begin{Prop}
	Se $X$ e $Y$ sono invarianti a sinistra allora anche $[X,Y]$, $cX$ e $X+Y$ lo sono. Inoltre, $[X,Y]$ rispetta l'identità di Jacobi. Quindi $Lie(G)$ è un'algebra di Lie.
\end{Prop}
\begin{proof}
	Dalla linearità della mappa differenziale segue che se $X,Y$ sono invarianti a sinistra anche le loro combinazioni lineari lo saranno.
	Per provare l'invarianza della bracket invece: si consideri un punto $p\in G$ ed una funzione $f\in C^\infty_p(G)$, si vuole far vedere che $dl_g([X,Y])=[X,Y]$.
	Applicando la definizione di differenziale: $$dl_g([X,Y]_p)f=[X,Y]_p(f\circ l_g)=$$$$=X_pY(f\circ l_g)-Y_pX(f\circ l_g)=$$$$=X_p(dl_g(Y)f)-Y_p(dl_g(X)f)=$$
	$$=X_p(Y(f)\circ l_g)-Y_p(X(f)\circ l_g)=$$
	$$=dl_g(X_p)Y(f)-dl_g(Y_p)X(f)=[X,Y]_{gp}f$$ 
	Per mostrare che è soddisfatta l'identità di Jacobi invece, presa una generica funzione $f\in C^\infty$ su $M$, si calcola:
	$$[X,[Y,Z]]f+[Y,[Z,X]]f+[Z,[X,Y]]f=$$
	$$=[X,YZ-ZY]f+[Y,ZX-XZ]f+[Z,XY-YX]f=$$
	$$=(XYZ-XZY-YZX+ZYX)f+(YZX-YXZ-ZXY+XZY)f+$$$$+(ZXY-ZYX-XYZ+YXZ)f=0$$
\end{proof}
Da ciò, $Lie(G)$ è un'algebra di Lie detta \textit{algebra di Lie di $G$} e si indica con $\mathfrak{g}$.
\begin{Theo}
	Dato un gruppo di Lie $G$, esiste un isomorfismo tra $Lie(G)$ e $T_eG$, cioè $Lie(G)\cong T_eG$.
\end{Theo}
Di seguito un cenno di dimostrazione. Per maggiori dettagli si veda: [2] pag. 51 cap. 2.
\begin{proof}
	Si consideri l'applicazione $f:X^A\mapsto A$ dove $X^A$ è un campo vettoriale invariante a sinistra e $A=X^A_e$, ovvero il vettore tangente di $X^A$ nell'identità.
	Si vuole provare che la mappa $g:A\mapsto X^A$, con $X^A$ generato da $A$, è l'inversa di $f$. Per verificare ciò è sufficiente mostrare che, dato $A$, $g(A)$ è invariante a sinistra. Ciò è vero per l'osservazione \ref{Obs: 2.2}.
\end{proof}
\begin{Obs}\label{Obs: bracket T}
	Possiamo definire un prodotto $[,]$ sullo spazio tangente all'identità in questo modo: presi due vettori $A,B\in T_eG$, definiamo $[A,B]=[X^A,X^B]_e$, dove $X^A$ e $X^B$ sono i campi invarianti a sinistra generati dai vettori scelti. E' possibile dimostrare che $X^{[A,B]}=[X^A,X^B]$. Per la dimostrazione si veda [1] pag. $183$ cap. $4$.
\end{Obs}
\begin{Ex}
	La varietà differenziabile $\mathbb{R}^n$ è un gruppo di Lie con l'operazione\\ $+:\mathbb{R}^n\rightarrow\mathbb{R}^n$ definita come: $(x_1,...,x_n)+(y_1,...,y_n)=(x_1+y_1,...,x_n+y_n)$. Lo stesso vale per $\mathbb{C}^n$.
	Considerando allora $\mathbb{C}^n$ e $\mathbb{R}^n$, le algebre di Lie associate sono rispettivamente $\mathbb{C}^n$ e $\mathbb{R}^n$ con le bracket banali $[X,Y]=0$. In $\mathbb{R}^2$, ciò equivale a chiedere che valga il lemma di Schwarz: ${\partial\over\partial y}{\partial\over\partial x}f(p)={\partial\over\partial x}{\partial\over\partial y}f(p)$.
\end{Ex}
Diamo ora alcuni esempi di spazi tangenti nell'identià per gruppi di matrici, ricordando che possiamo identificare questi spazi con l'algebra di Lie dei gruppi stessi.
\begin{Ex}
	Indichiamo con $\mathfrak{gl_n(\mathbb{R})}$ l'algebra di Lie di $GL_n(\mathbb{R})$.
	Per l'osservazione \ref{Obs 1.1.3}, si ha $T_\mathbb{I}GL_n(\mathbb{R})=T_\mathbb{I}M_{n\times n}=M_{n\times n}$. Da ciò, $$\mathfrak{gl_n(\mathbb{R})}\cong M_{n\times n}= T_\mathbb{I}GL_n(\mathbb{R})$$
	Inoltre è possibile verificare che la bracket dell'osservazione \ref{Obs: bracket Mnn} coincide con quella dell'osservazione \ref{Obs: bracket T}.
\end{Ex}
\begin{Ex}
	Indichiamo con $\mathfrak{sl_n(\mathbb{R})}$ l'algebra di Lie di $SL_n(\mathbb{R})=\{A\in M_{n\times n}|det(A)=1\}$.
	Consideriamo una curva $\gamma:]-\epsilon,\epsilon[\rightarrow M_{n\times n}$ tale che $\gamma(t)=\mathbb{I}+tB+O(t^2)$, è necessario che $det(\mathbb{I}+tB+O(t^2))=1$. Ma $det(\mathbb{I}+tB+O(t^2))=1+tr(B)+O(t^2)$ da cui: $$T_\mathbb{I}SL_n(\mathbb{R})\cong \mathfrak{sl_n(\mathbb{R})}=\{A\in M_{n\times n}|trA=0\}$$ 
\end{Ex}
\begin{Ex}
	Sia lo spazio $GL(V)=\{f:V\rightarrow V|\, \textnormal{$f$\,  è \, lineare \, e \, invertibile}\}$ dove $V$ è uno spazio vettoriale a dimensione finita. Indichiamo con $\mathfrak{gl}(V)$ l'algebra di Lie di $GL(V)$.  Allora, fissata una base di $V$, si ha l'identificazione $GL(V)\cong GL_n(\mathbb{R})$. Lo spazio tangente a $GL_n(\mathbb{R})$ è stato provato essere $M_{n\times n}(\mathbb{R})\cong End(V)=\{f:V\rightarrow V|\textnormal{\, $f$\, è \, lineare}\}$. Da cui: 
	$$\mathfrak{gl}(V)\cong T_{id}GL(V)\cong End(V)$$ 
\end{Ex}
Per la caratterizzazione delle algebre di Lie di $O_n(\mathbb{R})$ e $SU_n(\mathbb{C})$ si farà uso della mappa esponenziale, che verrà discussa nella successiva sezione.
\section{Mappa esponenziale}
In questa sezione daremo la definizione ed enunceremo alcune proprietà della mappa esponenziale e delle sue applicazioni. In particolare, ci concentreremo sui gruppi di matrici. Per tutti i dettagli si veda [4] parte 1, cap 2-2.4 e 3.7.
\begin{Def}
	Dato $G$ gruppo di Lie e $X\in\mathfrak{g}$, la \textit{mappa esponenziale} \\$exp:\mathfrak{g}\rightarrow G$ è definita come $exp(X)=\Phi_X(1,e)$ flusso del campo $X$.
\end{Def}
Si indicherà $exp(X)$ anche come $e^X$.
\begin{comment}
La mappa esponenziale verifica numerose proprietà, in particolare per i gruppi di Lie di matrici.
\begin{Prop}
Sia un gruppo di Lie di matrici, allora valgono le seguenti proprietà per la mappa esponenziale:\begin{itemize}
\item $exp(tX)=\Phi_X(t,e)$ per ogni $X\in \mathfrak{g}$ e $t\in \mathbb{R}$;
\item $exp((t+s)X)=exp(tX)\circ exp(sX)$ per ogni $X\in \mathfrak{g}$ e $s,t\in\mathbb{R}$;
\item $exp$ è analitica ed è un diffeomorfismo di un intorno di $0\in\mathfrak{g}$ in un intorno di $e\in G$;
\item ${d\over dt}\bigg{\rvert}_0exp(tX)=X$. 
\end{itemize}
\end{Prop}
Per le dimostrazioni si faccia riferimento a [2] (pag. 85, 86 cap. 2) e [3] (pag. 23 cap. 1).\\
\\
Prima di enunciare altre proprietà, è necessario definire l'esponenziale di matrice.%%
\end{comment}
\begin{Def}
	Si dice \textit{esponenziale} di una matrice $X\in M_{n\times n}$ la serie \\$e^X=\sum_{n=0}^{\infty}{X^n\over n! }$ dove $X^n$ è il prodotto ripetuto $n$ volte di $X$ con sè stessa.
\end{Def}
Si può dimostrare che questa serie converge per ogni $X\in M_{n\times n}$ ed è una funzione continua di $X$. Inoltre valgono:\begin{itemize}
	\item $e^0=I$;
	\item $(e^X)^+=e^{X^+}$ dove con $^+$ si è indicata l'aggiunzione;
	\item $e^X$ è invertibile ed $(e^X)^{-1}=e^{-X}$;
	\item $e^{(a+b)X}=e^{aX}e^{bX}$ per ogni $a,b\in\mathbb{R}$;
	\item se $XY-YX=0$ allora $e^{X+Y}=e^Xe^Y=e^Ye^X$ per ogni $X,Y$ matrici;\\
	\item se $C$ è una matrice invertibile, allora $e^{CXC^{-1}}=Ce^XC^{-1}$
\end{itemize} 
Ma il risultato forse più importante è che ${d\over dt}e^{tX}\bigg{\rvert}_0=X$ e ${d\over dt}e^{tX}\bigg{\rvert}_{t'}=Xe^{t'X}$.\\
Infatti, quest'ultima proprietà ci assicura che la mappa esponenziale coincida con l'esponenziale di matrice.
Per le dimostrazioni consultare [4] pag. 38-41 cap.2.\\
\\
Utilizzando la mappa esponenziale è possibile trovare un'espressione per l'algebra di Lie di gruppi di matrici come $U_n(\mathbb{R})$ e $O_n(\mathbb{R})$. Si consideri il seguente esempio:
\begin{Ex}[Spazio tangente a $O_n(\mathbb{R})$]
	Si indica con $\mathfrak{o_n(\mathbb{R})}$ l'algebra di Lie di $O_n(\mathbb{R})=\{A\in M_{n\times n}|A^T=A^{-1}\}$.\\
	Data una curva passante per $\mathbb{I}$ come $e^{tX}$, affinché essa sia contenuta dentro $O_n(\mathbb{R})$, deve valere $(e^{tX})^T=(e^{tX})^{-1}=e^{-tX}$, che è vero solamente se $-X=X^T$. Da ciò: $$\mathfrak{o_n(\mathbb{R})}=\{X\in M_{n\times n}|-X=X^T\}$$
	Lo stesso ragionamento si può fare con il gruppo $U_n(\mathbb{R})$, ottenendo: $$\mathfrak{u_n(\mathbb{R})}=\{X\in M_{n\times n}|-X=X^+\}$$
\end{Ex}
Enunciamo ora un importante risultato che ci permetterà di stabilire un collegamento, attraverso la mappa esponenziale, tra omomorfismi di gruppi e algebre di Lie.
\begin{Prop} \label{Prop: 2.4.1}
	Siano $G$ e $H$ gruppi di Lie di matrici e $\mathfrak{g}$, $\mathfrak{h}$ le loro algebre. Sia $\rho:G\rightarrow H$ un omomorfismo tra gruppi di Lie. Allora esiste un'unica mappa reale lineare $q:\mathfrak{g}\rightarrow\mathfrak{h}$ tale che:
	\begin{itemize}
		\item $\rho(e^X)=e^{q(X)}$; 
		\item $q(AXA^{-1})=\rho(A)q(X)\rho(A)^{-1}$;
		\item $q([X,Y])=[q(X),q(Y)]$, cioè è omomorfismo tra algebre di Lie;
		\item $q(X)={d\over dt}\bigg{\rvert}_0\rho(e^{tX})$.
	\end{itemize}
\end{Prop}
Per la dimostrazione si veda [4] pag.67 cap. 3.\\
\\
Da questo risultato emerge che dato un qualunque omomorfismo tra gruppi di Lie di matrici, esso genera un unico omomorfismo tra le algebre di questi gruppi.
\chapter{Teoria della Rappresentazione}
\label{chap:3}
In questo capitolo si definirà che cos'è una rappresentazione di un gruppo, si enunceranno alcuni risultati importanti e si studieranno alcuni particolari esempi di grande rilevanza per la fisica.
Per approfondimenti su questi temi si vedano [3] cap. 2; [4] parte 1, cap 4; [6] cap. 9 e cap. 3.
\section{Rappresentazioni di gruppi}
In questa sezione diamo la definizione di rappresentazione di un gruppo e di un gruppo di Lie e ne esponiamo alcune proprietà e teoremi. Per maggiori dettagli si veda [4] parte 1, cap 4 e [6] cap. 3.
Come vedremo, sarà possibile studiare le rappresentazioni di un gruppo attraverso quelle della sua algebra di Lie.
\begin{Def}
Dato un gruppo $G$ e uno spazio vettoriale $V$ di dimensione finita, si dice \textit{rappresentazione} un omomorfismo di gruppi $\rho:G\rightarrow GL(V)$. In altre parole, chiediamo $\rho(gh)=\rho(g)\circ\rho(h)$ per ogni $g,h\in G$.\\
Se $G$ è un gruppo di Lie, si definisce una rappresentazione di un gruppo di Lie come una mappa di gruppi di Lie $\rho:G\rightarrow GL(V)$. Con \textit{dimensione della rappresentazione} si intenderà la dimensione dello spazio vettoriale $V$.
\end{Def}
In generale, se non altrimenti specificato, gli spazi vettoriali $V$ menzionati saranno a dimensione finita. Tuttavia è possibile anche dare una definizione più generale.
\begin{Obs}
	Equivalentemente, si può definire una rappresentazione come un'azione del gruppo su di uno spazio vettoriale (come visto nel capitolo \ref{Chap: 2} sezione \ref{Sec:2.1}):
	$$a:G\times V\rightarrow V$$
	tale che $a(e,x)=x$ e $a(gh,v)=a(g,a(h,v))$.\\
	E' facile vedere come le due definizioni siano equivalenti: data una, è completamente definita l'altra: infatti, data un'azione $a:G\times V\rightarrow V$, possiamo definire $\rho:G\rightarrow GL(V)$ come $\rho(g)v=a(g,v)$. In questo caso si ha che $$\rho(gh)v=a(gh,v)=a(g,a(h,v))=\rho(g)\circ\rho(h)v$$
		Se invece è data una rappresentazione $\rho:G\rightarrow GL(V)$, allora definiamo $a:G\times V\rightarrow V$ come $a(g,v)=\rho(g)v$. Allora $$a(gh,v)=\rho(gh)v=\rho(g)\circ\rho(v)v=a(g,a(h,v))$$
\end{Obs}
Vediamo ora alcuni esempi di rappresentazioni:
\begin{Ex}[Rappresentazione banale]
	Sia $G$ un gruppo di Lie di matrici. Si definisca $\rho: G\rightarrow GL_n(\mathbb{C})$ tale che $\rho(X)=I$, allora $\rho$ è una rappresentazione, detta rappresentazione banale. 
\end{Ex}
\begin{Ex}[Rappresentazione standard]
	Sia $G$ un gruppo di Lie di matrici. Allora per definizione $G\subset GL_n(\mathbb{C})$. Si definisca $\rho: G\rightarrow GL_n(\mathbb{C})$ come $\rho(X)=X$, allora $\rho$ è una rappresentazione, detta rappresentazione standard. 
\end{Ex}
\begin{Def}
	Data un rappresentazione di un gruppo di Lie $\rho$ che agisce su di uno spazio $V$, un sottospazio $W\subset V$ è detto \textit{invariante} se $\rho(g)w\in W$ per ogni $w\in W$.
	Una rappresentazione i cui unici sottospazi invarianti sono $\{0\}$ e $V$ è detta \textit{irriducibile}.
\end{Def}
\section{Rappresentazioni di algebre di Lie}
Vogliamo ora dare la definizione di rappresentazione di un'algebra di Lie. Come vedremo, le rappresentazioni di algebra e gruppo di Lie sono strettamente legate tra loro.
\begin{Def}
	Sia $\mathfrak{g}$ algebra di Lie. Una rappresentazione di $\mathfrak{g}$ è un morfismo di algebre di Lie $\pi:\mathfrak{g}\rightarrow End(V)$; dove $V$ è spazio vettoriale finito-dimensionale. Dunque $\pi([X,Y])=[\pi(X),\pi(Y)]$.
\end{Def}
\begin{comment}
Così come per i gruppi, anche per le algebre abbiamo l'equivalenza tra le nozioni di azioni e gruppi. Infatti, data una rappresentazione.
\end{comment}
Enunciamo ora una serie di risultati che ci permetteranno di dimostrare l'irriducibilità di una rappresentazione di un gruppo di Lie a partire da quella della sua algebra.
\begin{Theo}
	Sia $G$ un gruppo di Lie di matrici con $\mathfrak{g}$ algebra di Lie e sia $\rho:G\rightarrow GL(V)$ una rappresentazione. Allora esiste unica una rappresentazione indotta dell'algebra di Lie di $G$, indicata con $d\rho:\mathfrak{g}\rightarrow \mathfrak{gl}(V)\equiv End(V)$ tale che $\rho(e^{tX})=e^{d\rho(X)}$ e $d\rho(X)={d\over dt}\rho(e^{tX})|_0$.\
	Inoltre $d\rho(AXA^{-1})=\rho(A)d\rho(X)\rho(A)^{-1}$.	
\end{Theo}
\begin{proof}
	A patto di fissare una base, possiamo identificare $GL(V)$ con $GL_n(\mathbb{C})$ (o $\mathbb{R}$), allora se assumiamo le ipotesi del teorema, $\rho$ diventa un omomorfismo tra gruppi di Lie di matrici. Per la proposizione \ref{Prop: 2.4.1} esiste un'unica $\varphi:\mathfrak{g}\rightarrow End(V)$ che coincide con $d\rho$ e rispetta tutte le proprietà.
\end{proof}
\begin{Theo}\label{Theo: 3.1}
	Sia $G$ gruppo di Lie di matrici connesso, $\mathfrak{g}$ la sua algebra $\rho:G\rightarrow GL(V)$ una rappresentazione e $d\rho:\mathfrak{g}\rightarrow \mathfrak{gl}(V)$ la rappresentazione indotta. Allora $\rho$ è irriducibile se e solo se $d\rho$ lo è.
\end{Theo}
Per la dimostrazione consultare [4] pag. 87 cap. 4.\\
\\
Dunque dato un gruppo di Lie di matrici connesso ed una sua rappresentazione, non solo è sempre possibile trovare una rappresentazione della sua algebra di Lie, ma l'irriducibilità dell'una equivale a quella dell'altra.
\begin{Def}
	Sia $\mathfrak{g}$ un'algebra di Lie reale. Si dice \textit{complessificazione} di $\mathfrak{g}$ lo spazio $\mathfrak{g_c}=\{X+iY|X,Y\in\mathfrak{g}\}$.
\end{Def}
E' possibile dimostrare che la parentesi di Lie ha un'unica estensione su $\mathfrak{g_c}$ data da:
$$[X_1+iX_2,Y_1+iY_2]=([X_1,Y_1]-[X_2,Y_2])+i([X_1,Y_2]+[X_2,Y_1])$$
Per la dimostrazione si veda [4] pag. 71, cap. 3.\\
\begin{Ex}
La complessificazione di $\mathfrak{su_2(\mathbb{C})}$ è data, per definizione, da $$\mathfrak{su_2(\mathbb{C})_c}=\{X+iY|X,Y\in M_{n\times n} ;X^{+}=-X;Y^{+}=-Y;tr(X)=tr(Y)=0\}$$
E' possibile dimostrare che $\mathfrak{su_2(\mathbb{C})_c}\cong \mathfrak{sl_2(\mathbb{C})}$. Per la dimostrazione si veda [4] pag. 72 cap.3.
\end{Ex}
Vale inoltre il seguente teorema, che ci permetterà di studiare l'irriducibilità di una rappresentazione attraverso l'estensione di essa sull'algebra complessificata.
\begin{Theo}
	Se $\mathfrak{g}$ è algebra di Lie e $\mathfrak{g_c}$ la sua complessificazione, allora ogni rappresentazione finito-dimensionale complessa  $d\rho$ di $\mathfrak{g}$ ha un'unica estensione su $\mathfrak{g_c}$. Inoltre $d\rho$ è irriducibile se e solo se lo è $d\rho_c$ estensione di $d\rho$.
\end{Theo}
\begin{proof}
	Si definisce $d\rho_c$ come $d\rho_c(X+iY)=d\rho(X)+id\rho(Y)=d\rho(X+iY)$ che è omomorfismo in quanto: 
	$$[d\rho(X+iY),d\rho(A+iB)]=[d\rho(X)+id\rho(Y),d\rho(A)+id\rho(B)]=$$$$=[d\rho(X),d\rho(A)+id\rho(B)]+i[d\rho(Y),d\rho(A)+id\rho(B)]=$$
	$$=[d\rho(X),d\rho(A)]+i[d\rho(X),d\rho(B)]+i[d\rho(Y),d\rho(A)]-[d\rho(Y),d\rho(B)]=$$
	$$=d\rho([X,A])+id\rho([X,B])+id\rho([Y,A])-d\rho([Y,B])=$$
	$$=d\rho([X,A]-[Y,B])+id\rho([X,B]+[Y,A])=$$
	$$=d\rho([X,A]+[iY,iB])+d\rho([X,iB]+[iY,A])=$$
	$$=d\rho([X+iY,A+iB])$$
	Per quanto riguarda l'irriducibilità, un sottospazio $W\subset V$ invariante per $d\rho(X+iY)$ lo è se e solo se lo è anche per $d\rho(X)$ e $d\rho(Y)$.
\end{proof}
Sappiamo che ogni rappresentazione di un gruppo di Lie di matrici $G$ definisce una rappresentazione dell'algebra $\mathfrak{g}$ di $G$.
Si può verificare che, per un gruppo di Lie di matrici semplicemente connesso, esiste una corrispondenza biunivoca tra le rappresentazioni di $G$ e quelle della sua algebra $\mathfrak{g}$. Per approfondimenti si veda [4] pag. 106 cap. 4.
\section{I gruppi $SU_2(\mathbb{C})$ e $SO_3(\mathbb{R})$} 
In questa sezione utilizzeremo i risultati enunciati precedentemente per lo studio di alcuni gruppi di matrici. Per maggiori dettagli si veda [6] cap. 9 e cap. 3.\\
\\
Definiamo il gruppo delle matrici speciali unitarie $$SU_2(\mathbb{C})=\{A\in M_{n\times n}|AA^{+}=I=A^{+}A;det(A)=1\}$$.
\begin{Prop}
	$A\in SU_2(\mathbb{C})$ se e solo se $A$ nella forma $A=
	\begin{pmatrix}
		\alpha & \beta \\
		-\bar{\beta} & \bar{\alpha}
	\end{pmatrix}
	$ con $|\alpha|^2+|\beta|^2=1$.
\end{Prop}
\begin{proof}
	Se $A$ è in questa forma allora $det(A)=1$ e $AA^{+}=I=A^{+}A$.\\
	Se invece $A\in SU_2(\mathbb{C})$ tale che $A=
	\begin{pmatrix}
		a & b \\
		c & d
	\end{pmatrix}$, allora possiamo scriverne l'inversa:
$A^{-1}=\begin{pmatrix}
	d & -b \\
	-c & a
\end{pmatrix}$ e l'aggiunta: $A^+=
\begin{pmatrix}
	\bar{a} & \bar{c} \\
	\bar{b} & \bar{d}
\end{pmatrix}$.\\
Queste due devono coincidere, ovvero: $d=\bar{a}$; $-b=\bar{c}$; $a=\bar{d}$; $-c=\bar{b}$. Questo verifica la proposizione.
\end{proof}
Abbiamo dimostrato che il gruppo $SU_2(\mathbb{C})$ coincide con il gruppo dei quaternioni con determinante 1.
Inoltre, dato che $\alpha=x_1+ix_2$ e $\beta=x_3+ix_4$, con $x_i\in\mathbb{R}$, si può identificare $SU_2(\mathbb{C})$ con la sfera quadridimensionale $$S^3=\{(x_1,x_2,x_3,x_4)\in \mathbb{R}^4|\sum x_i^2=1\}$$
Da questa identificazione segue che, essendo $S^3$ connessa, compatta e semplicemente connessa, tutte queste proprietà sono anche di $SU_2(\mathbb{C})$.
\\\\
Definiamo ora il gruppo delle matrici speciali ortogonali indicato con $$SO_3(\mathbb{R})=\{A\in M_{n\times n}|A^{-1}=A^T, det(A)=1\}$$
E' possibile dimostrare che il gruppo $SO_3(\mathbb{R})$ è connesso ma non semplicemente connesso. Per approfondimenti su questo risultato si veda [4] pag. 26-28 cap.1.
\section{I quaternioni}
In questa sezione introduciamo il gruppo dei quaternioni, che utilizzeremo per studiare le rappresentazioni di $SO_3(\mathbb{R})$. Per maggiori dettagli si veda [6] cap. 9.\\
\\
Definiamo l'insieme dei quaternioni:
$$H=\bigg{\{}
\begin{pmatrix}
	\alpha & \beta \\
	-\bar{\beta} & \bar{\alpha}
\end{pmatrix}
\bigg{\rvert}\alpha,\beta\in \mathbb{C}
\bigg{\}}$$
Questo insieme, munito delle operazioni di prodotto righe per colonne e somma tra matrici, è un'algebra reale avente come base le matrici:
$$\mathbb{I}=\begin{pmatrix}
	1 & 0 \\
	0 & 1
\end{pmatrix};
i=\begin{pmatrix}
	i & 0 \\
	0 & -i
\end{pmatrix};
j=\begin{pmatrix}
	0 & 1 \\
	-1 & 0
\end{pmatrix};
k=\begin{pmatrix}
	0 & i \\
	i & 0
\end{pmatrix}$$
Inoltre, ogni $X$ non nullo in $H$ ha come inverso l'elemento $X^*/det(X)^2$, dove con $^*$ si è indicata l'operazione di trasposizione e coniugazione.\\
\\
Prendendo un generico quaternione $X$ individuato dalla coppia $(\alpha,\beta)$ e sostituendo $\alpha=x_1+ix_2$, $\beta=x_3+ix_4$; questo stesso quaternione potrà essere espresso come $X=\mathbb{I}x_1+ix_2+jx_3+kx_4$ dove $i,j,k$ sono le matrici definite sopra. E' allora possibile definire una norma nello spazio $H$ come $||X||=x_1^2+x_2^2+x_3^2+x_4^2=det(X)=\sum_{i=1}^{4}x_i^2$.\\
\\
Si consideri poi l'insieme $H_0$ di tutti i quaternioni tali che $X^*=-X$, chiamati \textit{puramente immaginari}. Affinchè un generico $X=\begin{pmatrix}
	\alpha & \beta \\
	-\bar{\beta} & \bar{\alpha}
\end{pmatrix}$ sia puramente immaginario è necessario che $\alpha+\bar{\alpha}=0$; ovvero che $\alpha=ix_2$ e $x_1=0$.\\
Questo significa che ogni quaternione puramente immaginario è individuato da una terna $X=(x_2,x_3,x_4)$ e la base di $H_0$ è $\{i,j,k\}$. Possiamo allora esprimere ogni $X\in H_0$ come
$\begin{pmatrix}
	ix_2 & x_3+ix_4\\
	-x_3+ix_4 & -ix_2\\
\end{pmatrix}$.
\begin{Obs} \label{Obs:3.4.1}
	Il fatto che $H_0$ abbia una base costituita da tre elementi implica che esista un isomorfismo tra esso e lo spazio $\mathbb{R}^3$.
\end{Obs}
Dato un $q$ non nullo, si definisca ora l'operatore di coniugazione
$T(q):H\longrightarrow H$ tale che
$$a\longrightarrow qaq^{-1}$$
\begin{Prop}
	Se $a\in H_0$ allora $-T(q)(a)=(T(q)(a))^*$, cioè $T(q)(a)\in H_0$. Inoltre, l'operatore di coniugazione $T(q)$ conserva la norma, ovvero $||T(q)(a)||=||a||$.
\end{Prop}
\begin{proof}
	Si supponga che $a\in H_0$ sia un quaternione puramente immaginario. Allora $$(T(q)(a))^*=(qaq^{-1})^*=(q^{-1})^*a^*q^*$$
	Dato che $q$ per ipotesi è non nullo, si può sostituire a $q^{-1}$ il suo inverso $q^*/det(q)^2$:
	$$(q^{-1})^*a^*q^*=({q^*\over det(q)^2})^*a^*q^*=q(-a)({q^*\over det(q)^2})$$
	dove nell'ultimo passaggio abbiamo spostato il denominatore dal primo all'ultimo termine. Sostituendo ancora una volta $q^{-1}=q^*/det(q)^2$ nell'espressione, otteniamo:
	$$(T(q)(a))^*=-qaq^{-1}$$
	Questo prova la prima parte della proposizione.\\
	\\
	Per verificare la conservazione della norma si utilizza il teorema di Binet:
	$$det(qaq^{-1})=det(q)det(a)det(q^{-1})$$
	Ricordando poi che $det(q^{-1})=det(q)^{-1}$ si ottiene:
	$$det(qaq^{-1})=det(a)$$
	Questo completa la dimostrazione.
\end{proof}
\section{Le rappresentazioni di $SO_3(\mathbb{R})$}
In questa sezione utilizziamo i risultati precedenti per studiare le rappresentazioni del gruppo di matrici $SO_3(\mathbb{R})$. Per maggiori dettagli si veda [6] pag. 46-48 cap. 9.\\
\\
Iniziamo con un'osservazione relativa all'operatore $T(q)$ introdotto nella sezione precedente con l'osservazione \ref{Obs:3.4.1}.
\begin{Obs}
	Identificando $H_0$ con lo spazio $\mathbb{R}^3$, si può vedere $T(q)|_{H_0}$ come un operatore da $\mathbb{R}^3$ a $\mathbb{R}^3$ che preserva la norma euclidea.\\
	Inoltre, l'operatore $T(q)$ è lineare. Infatti, prese due matrici $a,b$ e uno scalare $\alpha$, applicando le proprietà del prodotto e della somma tra matrici: $$T(q)(a+b)=q(a+b)q^{-1}=qaq^{-1}+qbq^{-1}=T(q)(a)+T(q)(b)
	$$
	$$T(q)(\alpha a)=\alpha T(q)(a)$$
	Ciò significa che, indicando con $H'$ l'insieme dei quaternioni non nulli, possiamo definire un omomorfismo $T':H'\rightarrow O_3(\mathbb{R})$ tale che
	$$q\longmapsto T(q)\bigg{\rvert}_{H_0}$$
\end{Obs}
Andiamo ora a studiare la restrizione della mappa appena definita all'insieme $SU_2(\mathbb{C})$. Vale la seguente proposizione:
\begin{Prop}
	Ogni operatore $T(q)|_{H_0}$ ottenuto a partire da una matrice di $SU_2(\mathbb{C})$ ha determinante uguale a $1$. Ovvero $T'(SU_2(\mathbb{C}))\subseteq SO_3(\mathbb{R})$. 
\end{Prop}
\begin{proof}
	Si ricorda che il determinante di una matrice $O_3(\mathbb{R})$ ortogonale è sempre pari a $\pm 1$.
	Si consideri ora la mappa $\xi:SU_2(\mathbb{C})\longrightarrow \{-1,1\}$ definita come $\xi(q)=det(T(q)|_{H_0})$.\\
	Ricordando che l'insieme $SU_2(\mathbb{C})$ è connesso e che la mappa determinante è continua, l'immagine di $det$ dovrà essere anche essa continua, cioè potrà assumere solamente un valore tra $-1$ e $1$.\\
	Dato che $\mathbb{I}\in SU_2(\mathbb{C})$ e $\xi(I)=det(I)=1$, allora $\xi(q)=1$ per ogni $q\in SU_2(\mathbb{C})$.
\end{proof}
Si è quindi dimostrato che 
$$T'\bigg{\rvert}_{SU_2(\mathbb{C})}:SU_2(\mathbb{C})\longrightarrow SO_3(\mathbb{R})$$
\begin{Obs} \label{Obs:3.2.3.1}
	Calcolando il nucleo di $T'$:$$KerT'=\{q\in SU_2(\mathbb{C})| T(q)=id\}=\{q\in SU_2(\mathbb{C})|qaq^{-1}=a, \forall a\in SU_2(\mathbb{C})\}=\{\pm\mathbb{I}\}$$
	Ciò suggerisce l'esistenza di una mappa 2:1 tra $SU_2(\mathbb{C})$ e $SO_3(\mathbb{R})$, che risulterà esistere tra $SU_2(\mathbb{C})/{\pm \mathbb{I}}$ e $SO_3(\mathbb{R})$.\\
	Per definizione: data la relazione di equivalenza $a\sim b$ se e solo se $b=a\{\pm \mathbb{I}\}$, allora
	$$SU_2(\mathbb{C})/{\pm \mathbb{I}}=\{[a], a\in SU_2(\mathbb{C})\}$$
	L'insieme $SU_2(\mathbb{C})/{\pm \mathbb{I}}$ è costituito da tutte le classi laterali $a\{\pm\mathbb{I}\}$, ovvero da tutte le matrici $SU_2(\mathbb{C})$ a meno del loro segno.
\end{Obs}
\begin{Prop} \label{prop:3.5.1}
	$SU_2(\mathbb{C})/{\pm \mathbb{I}}\cong SO_3(\mathbb{R})$ e l'isomorfismo è precisamente la mappa $T':SU_2(\mathbb{C})/{\pm \mathbb{I}}\longrightarrow SO_3(\mathbb{R})$ definito come $T'(q)=T(q)$.
\end{Prop}
\begin{proof}
	L'iniettività è automaticamente provata dall'osservazione \ref{Obs:3.2.3.1}. Rimane da provare la suriettività.
	Si consideri il quaternione 
	$$q(\theta)=
	\begin{pmatrix}
		e^{i\theta} & 0\\
		0 & e^{-i\theta}\\
	\end{pmatrix}=cos(\theta)+isin(\theta)$$
dove $\theta\in [0,2\pi]$. Calcolando $T(q(\theta))(a)=q(\theta)aq(\theta)^{-1}$ con $a\in H_0$, si ottiene:
$$\begin{pmatrix}
	e^{i\theta} & 0\\
	0 & e^{-i\theta}\\
\end{pmatrix}
\begin{pmatrix}
	ix_2 & x_3+ix_4\\
	-x_3+ix_4 & -ix_2\\
\end{pmatrix}
\begin{pmatrix}
e^{-i\theta} & 0\\
0 & e^{i\theta}\\
\end{pmatrix}=$$
$$\begin{pmatrix}
	e^{-i\theta}(ix_2) & e^{i\theta}(x_3+ix_4)\\
	e^{-i\theta}(-x_3+ix_4) & e^{-i\theta}(-ix_2)\\
\end{pmatrix}
\begin{pmatrix}
	e^{-i\theta} & 0\\
	0 & e^{i\theta}\\
\end{pmatrix}=$$
$$\begin{pmatrix}
	ix_2 & e^{2i\theta}(x_3+ix_4)\\
	e^{-2i\theta}(-x_3+ix_4) & -ix_2\\
\end{pmatrix}$$
Si valuta ora il termine $e^{2i\theta}(x_3+ix_4)$. Riscriviamo il numero complesso $(x_3+ix_4)$ come $(x_3+ix_4)=r(cos(\alpha)+isin(\alpha))$ dove $r=\sqrt{x_3^2+x_4^2}$. Valutiamo ora l'espressione 
$$e^{2i\theta}r(cos(\alpha)+isin(\alpha))=
(cos(2\theta)+isin(2\theta))r(cos(\alpha)+isin(\alpha))=$$
$$=r(cos(2\theta)cos(\alpha)+icos(2\theta)sin(\alpha)+isin(2\theta)cos(\alpha)-sin(2\theta)sin(\alpha))=$$
$$r(cos(2\theta+\alpha)+isin(2\theta+\alpha))$$
Si è trovato che una matrice del tipo $q(\theta)=cos(\theta)+isin(\theta)$ fissa $i$ e induce nel piano generato da $j,k$ una rotazione di un angolo pari a $2\theta$. Con dei calcoli analoghi si può vedere che i quaternioni del tipo $cos(\theta)+jsin(\theta)$ e $cos(\theta)+ksin(\theta)$ fissano $j$ e $k$ e inducono una rotazione di $2\theta$ nel piano generato dai rimanenti elementi della base.\\
E' noto che componendo tali rotazioni si ottiene ogni elemento di $SO_3(\mathbb{R})$. Dunque, la mappa $T':SU_2(\mathbb{C})/{\pm \mathbb{I}}\longrightarrow SO_3(\mathbb{R})$ è anche suriettiva e quindi è isomorfismo.\\
Questo conclude la dimostrazione.
\end{proof}
\begin{Obs} \label{Obs:3.5.1}
	Questa proposizione permette di descrivere le rappresentazioni di $SO_3(\mathbb{R})$ attraverso quelle di $SU_2(\mathbb{C})$. \\
	Si consideri una generica rappresentazione di $SU_2(\mathbb{C})$ indicata con $\rho$. Per definizione $\rho:SU_2(\mathbb{C})\rightarrow GL(V)$ è un omomorfismo, ovvero $\rho(gh)=\rho(g)\circ\rho(h)$. Allora, data una matrice $a\in SU_2(\mathbb{C})$, possiamo scrivere:
	$$\rho(\pm a)=\rho(\pm \mathbb{I}a)=\rho(\pm\mathbb{I})\rho(a)$$
	Se $\rho$ ha come nucleo l'insieme $Ker\rho=\{\pm\mathbb{I}\}$, allora
	$$\rho(\pm a)=\rho(a)$$
	In questo caso è automaticamente definita una rappresentazione $\rho':SU_2(\mathbb{C})/\pm\mathbb{I}\longrightarrow GL(V)$ tale che $\rho'([a])=\rho(a)$.
	Allora, dato che esiste un isomorfismo tra $SO_3(\mathbb{R})$ e $SU_2(\mathbb{C})$, esiste anche una rappresentazione $\xi$ di $SO_3(\mathbb{R})$. In modo più formale, dato $T':SU_2(\mathbb{C})\rightarrow SO_3(\mathbb{R})$ isomorfismo e $\rho':SU_2(\mathbb{C})/\pm\mathbb{I}\longrightarrow GL(V)$ rappresentazione, la mappa $\xi=\rho'\circ T'^{-1}$ è una rappresentazione di $SO_3(\mathbb{R})$.
	Questo risultato può essere formalizzato nella proposizione:
\end{Obs}
\begin{Prop}
	Le rappresentazioni di $SO_3(\mathbb{R})$ sono le rappresentazioni di $SU_2(\mathbb{C})$ che hanno nel nucleo $\pm\mathbb{I}$. 
\end{Prop}
\begin{Obs}
	 $$T'\bigg{\rvert}_{SU_2(\mathbb{C})}:SU_2(\mathbb{C})\longrightarrow SO_3(\mathbb{R})$$
	 è un rivestimento in quanto rispetta la definizione \ref{Def: 2.2.2}. In particolare, dato che ogni matrice di $SU_2(\mathbb{C})$ viene mappata a meno del segno in una precisa matrice di $SO_3(\mathbb{R})$, diciamo che lo spazio $SU_2(\mathbb{C})$ copre due volte $SO_3(\mathbb{R})$. Inoltre, dal fatto che $SU_2(\mathbb{C})$ è anche semplicemente connesso, per definizione \ref{Def:2.2.1}, la mappa $T'$ è un rivestimento universale.
\end{Obs}
\section{Le rappresentazioni di $SU_2(\mathbb{C})$}
Andiamo ora a studiare le rappresentazioni di $SU_2(\mathbb{C})$. Questo esempio è estremamente utile in quanto mostra come sia molto più vantaggioso lavorare con le rappresentazioni delle algebre di Lie invece che con le rappresentazioni dei gruppi.\\
\\
La rappresentazione di gruppo che utilizzeremo sarà definita come azione sullo spazio dei polinomi omogenei in due variabili, che denotiamo con $V_m$.
	L'insieme $\{x^{m-i}y^i\}$ è base per $V_m$, che quindi ha dimensione $dim(V_m)=m+1$.
	\begin{comment}
		Sia $f(v)=f(x,y)$ un elemento di $V_m$ e $g$ un elemento di $SU_2(\mathbb{C})$ con inverso $g^{-1}$.\\
	Dunque, se $g\in SU_2(\mathbb{C})$ è nella forma $g=$
	$\begin{pmatrix}
	\alpha&\beta\\
	-\bar{\beta}&\bar{\alpha}
	\end{pmatrix}$,
	allora il suo inverso sarà $g^{-1}=
	\begin{pmatrix}
	\bar{\alpha}&-\beta\\
	\bar{\beta}&\alpha
	\end{pmatrix}$ dato che il determinante di $g$ è 1. \\
	Applicare $g^{-1}$ ad una coppia $(x,y)$ significa computare:
	$g^{-1}v=g^{-1}
	\begin{pmatrix}
	x\\y
	\end{pmatrix}=
	\begin{pmatrix}
	\bar{\alpha}x-\beta y\\
	\bar{\beta}x+\alpha y
	\end{pmatrix}$
	Da ciò $(g,f(x,y))\longmapsto f(\bar{\alpha}x-\beta y,\bar{\beta}x+\alpha y)$
	\end{comment}
\begin{Prop}
	Sia $V_m=\{\sum_{i=0}^{m} a_ix^{m-i}y^i\}$. La mappa $a:SU_2(\mathbb{C})\times V_m\rightarrow V_m$, $a(g,f(v))=f(g^{-1}v)$ è rappresentazione.
\end{Prop}
\begin{proof}
	Come dimostrato, data un'azione di gruppo è automaticamente definito un omomorfismo e viceversa. Allora possiamo definire la mappa $\rho:SU_2(\mathbb{C})\rightarrow GL(V_m)$ come $\rho(g)f(v)=a(g,f(v))$ con $g\in SU_2$ e $f(v)\in V_m$.
	Si vuole mostrare che $\rho$ è omomorfismo tra gruppi, ovvero $\rho(gh)=\rho(h)\circ\rho(h)$.\\
	Per definizione:
	$$\rho(gh)f(v)=a(gh,f(v))=f((gh)^{-1}v)$$
	Dato che, con l'usuale prodotto tra matrici, $(gh)^{-1}=h^{-1}g^{-1}$, si ha:
	$$\rho(g)[\rho(h)f](v)=[\rho(h)f](g^{-1}v)=f(h^{-1}g^{-1}v)=$$
	$$=f((gh)^{-1}v)=\rho(gh)f(v)$$
	Questo termina la dimostrazione.
\end{proof}
Verificato che la mappa scelta è effettivamente una rappresentazione, si procede a dimostrarne l'irriducibilità. Vale il seguente teorema:
\begin{Theo} \label{Theo1}
	Le $\rho$ rappresentazioni di $SU_2(\mathbb{C})$ che agiscono sullo spazio $V_m$ come definite sopra sono irriducibili per ogni $m\geq 0$ intero.
\end{Theo}
\begin{proof}
	Per provare l'irriducibilità ci serviamo della rappresentazione indotta sull'algebra di $SU_2(\mathbb{C})$. Infatti, utilizzando il Teorema \ref{Theo: 3.1}, se dimostriamo che questa è irriducibile, allora lo è anche la rappresentazione di gruppo in quanto $SU_2(\mathbb{C})$ è connesso. Inoltre, non agiamo direttamente su $\mathfrak{su_2(\mathbb{C})}$ ma su di uno spazio isomorfo alla sua complessificazione: $\mathfrak{sl_2(\mathbb{C})}$.\\
	\\
	La rappresentazione indotta sull'algebra è $d\rho:\mathfrak{sl_2(\mathbb{C})}\rightarrow \mathfrak{gl}(V_m)\equiv End(V_m)$ come 
	$$d\rho(X)f(x,y)={d\over dt}\bigg{\rvert}_{0}\rho(e^{tX})f(x,y)={d\over dt}\bigg{\rvert}_{0}f(e^{-tX}(x,y))$$
	In particolare, data la curva $z(t)=(x'(t),y'(t))=e^{-tX}(x,y)$ si ha 
	\begin{equation}
		d\rho(X)f={\partial f\over \partial x}{dx'\over dt}\bigg{\rvert}_0+{\partial f\over \partial y}{dy'\over dt}\bigg{\rvert}_0 \label{eq:1} \tag{1}
	\end{equation}
	
	Data una matrice  
	$X=\begin{pmatrix}
		X_{11}&X_{12}\\
		X_{13}&X_{14}
	\end{pmatrix}$ allora 
\begin{equation}
	\bigg{(}{dx'\over dt}\bigg{\rvert}_0,{dy'\over dt}\bigg{\rvert}_0\bigg{)}=-X(x,y)=-(X_{11}x+X_{12}y,X_{21}x+X_{22}y)\label{eq:2} \tag{2}
\end{equation}
Sostituendo le relazioni trovate in \ref{eq:2} dentro \ref{eq:1}
\begin{equation}
d\rho(X)f=-{\partial f\over \partial x}(X_{11}x+X_{12}y)-{\partial f\over \partial y}(X_{21}x+X_{22}y) \label{eq:3} \tag{3}
\end{equation}
	Si consideri poi la base di $\mathfrak{sl_2(\mathbb{C})}$ costituita dalle matrici $$H=
	\begin{pmatrix}
		1&0\\
		0&-1
	\end{pmatrix}; 
	X=\begin{pmatrix}
		0&1\\
		0&0
	\end{pmatrix};
	Y=\begin{pmatrix}
		0&0\\
		1&0
	\end{pmatrix}$$ allora, sostituendo i termini di queste matrici all'interno della relazione \ref{eq:3} si trovano le espressioni dei seguenti operatori:
\begin{equation*}
	d\rho(H)=-x{\partial\over\partial x}+y{\partial\over\partial y}
\end{equation*}

	\begin{equation*}
	d\rho(X)=-y{\partial\over\partial x}
\end{equation*}
	\begin{equation*}
	d\rho(Y)=-x{\partial\over\partial y}
\end{equation*}
	Applicando queste alla base di $V_m$ costituita dai vettori $\{x^{m-i}y^i\}$ si ottiene:
	$$d\rho(X)(x^{m-i}y^i)=-(m-i)x^{m-i-1}y^{i+1}$$
	$$d\rho(Y)(x^{m-i}y^i)=-ix^{m-i+1}y^{i-1}$$
	$$d\rho(H)(x^{m-i}y^i)=(-m+2i)x^{m-i}y^i$$
	Si osserva quindi che i vettori della base di $V_m$ sono autovettori di $d\rho(H)$ con autovalori $(-m+2i)$. L'effetto degli operatori $d\rho(X)$ e $d\rho(Y)$ è invece quello di alzare ed abbassare gli indici di $x$ e $y$.\\
	\\
	Per dimostrare l'irriducibilità, supponiamo che $W\subset V_m$ sia un sottospazio invariante per $d\rho$; cioè che $d\rho(A)w\in W$ per ogni $w\in W$ e per ogni $A\in \mathfrak{sl_2(\mathbb{C})}$. Cerchiamo di dimostrare che $W$ è banale. \\Poiché abbiamo fissato una base di $V_m$, un generico $w\in W$ si può scrivere come $w=\sum_{i=0}^{m}a_ix^{m-i}y^i$. Se supponiamo che $W\neq\{0\}$ allora esiste almeno un $a_i\neq 0$.
	Si indichi con $i_0$ il più piccolo indice per cui $a_i\neq 0$. \\
	Considerando $d\rho(X)^{m-i_0}w$, sapendo che $d\rho(X)^{m-i_0}(x^{m-i}y^i)\propto x^{i_0-i}y^{m+i-i_0}$, allora:
	\begin{itemize}
		\item se $0<i_0<i$, $\Rightarrow$ $d\rho(X)^{m-i_0}(x^{m-i}y^i)\propto 0$ dato che potrà essere applicato per un massimo di $m-i$ volte ($d\rho(X)x^0y^k=0$);
		\item se $i_0>i$ $\Rightarrow$ il coefficiente di $x^{m-i}y^{i}$ è nullo poiché abbiamo supposto che $i_0$ fosse il più piccolo indice per cui $a_{i_0}\neq 0$. 
		\item se $i_0=i$ $\Rightarrow$ $d\rho(X)^{m-i_0}(x^{m-i}y^i)\propto y^m$.
	\end{itemize} 
	Poiché si è supposto che $W$ fosse invariante, questi deve contenere tutti i multipli di $y^m$.\\
	Si scelga ora arbitrariamente un indice intero $k\in[0,m]$, e si valuti l'azione ripetuta di $d\rho(Y)$ su un elemento della base: $d\rho(Y)^ky^m\propto x^ky^{m-k}$.
	Per invarianza di $W$, $d\rho(Y)^ky^m\in W$. Allora $W$ deve contenere anche tutti i multipli di $x^ky^{m-k}$. Per arbitrarietà di $k$, $W$ contiene una base di $V_m$, cioè $W\equiv V_m$.\\
	Questo completa la dimostrazione.
\end{proof}
\section{Le rappresentaioni irriducibili di $\mathfrak{sl_2(\mathbb{C})}$}
In questa sezione studieremo le rappresentazioni irriducibili dell'algebra $\mathfrak{sl_2(\mathbb{C})}$, isomorfa alla complessificazione di $\mathfrak{su_2(\mathbb{C})}$. Mostreremo come tutte le rappresentazioni irriducibili di questa algebra di Lie abbiano la stessa forma.\\
\\
\begin{Obs}\label{Obs1}
	Considerando la base di $\mathfrak{sl_2(\mathbb{C})}$ composta dalle matrici: $$H=
	\begin{pmatrix}
		1&0\\
		0&-1
	\end{pmatrix}; 
	X=\begin{pmatrix}
		0&1\\
		0&0
	\end{pmatrix};
	Y=\begin{pmatrix}
		0&0\\
		1&0
	\end{pmatrix}$$
è possibile dedurre alcune importanti proprietà relative ai commutatori di esse:
\begin{itemize}
	\item $[X,Y]=H$;
	\item $[H,X]=2X$;
	\item $[H,Y]=-2Y$.
\end{itemize}
Queste relazioni si ottengono svolgendo esplicitamente i calcoli. Di seguito è riportato il conto esplicito della prima uguaglianza, le altre si ottengono in modo analogo.
$$[X,Y]=XY-YX=\begin{pmatrix}
	0&1\\
	0&0
\end{pmatrix}
\begin{pmatrix}
	0&0\\
	1&0
\end{pmatrix}-
\begin{pmatrix}
	0&0\\
	1&0
\end{pmatrix}
\begin{pmatrix}
	0&1\\
	0&0
\end{pmatrix}=$$$$=
\begin{pmatrix}
1&0\\
0&0
\end{pmatrix}-\begin{pmatrix}
0&0\\
0&1
\end{pmatrix}=H$$
\end{Obs}
\begin{Theo}\label{Theo2}
	Per ogni intero $m\geq 0$, esiste una rappresentazione irriducibile di dimensione $m+1$. Due rappresentazioni irriducibili di $\mathfrak{sl_2(\mathbb{C})}$ con la stessa dimensione sono isomorfe tra di loro. Inoltre, se $d\rho_1$ è rappresentazione irriducibile di dimensione $m+1$, allora è isomorfa a $d\rho:\mathfrak{sl_2(\mathbb{C})}\rightarrow End(V_m)$ come descritta sopra.
\end{Theo}
Per provare questo teorema sono necessari due lemmi. Il primo  è il seguente:
\begin{Lem}\label{Lemma1}
	Sia $v$ un autovettore di $d\rho(H)$ con autovalore $a\in\mathbb{C}$. Allora $d\rho(H)d\rho(X)v=(a+2)d\rho(X)v$ e $d\rho(H)d\rho(Y)v=(a-2)d\rho(Y)v$. Cioè o $d\rho(X)v$ e $d\rho(Y)v$ sono nulli, o sono autovettori di $d\rho(H)$ con autovalori $a+2$ e $a-2$.
\end{Lem}
\begin{proof}
	Dato che $d\rho$ è una rappresentazione di un'algebra, essa è un omomorfismo, cioè preserva il bracket:\\ $$d\rho([H,X])v=[d\rho(H),d\rho(X)]v$$
	Ma vale anche $$[d\rho(H),d\rho(X)]v=d\rho(H)d\rho(X)v-d\rho(X)d\rho(H)v$$ e, come calcolato nell'osservazione 2.15: $$[H,X]=HX-XH=2X$$ 
	Allora $$[d\rho(H),d\rho(X)]v=2d\rho(X)v=d\rho(H)d\rho(X)v-d\rho(X)d\rho(H)v$$ 
	Ricordando che $v$ è autovettore di autovalore $a$ di $d\rho(H)$:
	$$d\rho(H)d\rho(X)v-d\rho(X)d\rho(H)v=d\rho(H)d\rho(X)v-d\rho(X)av=2d\rho(X)v$$ da cui
	$$d\rho(H)d\rho(X)=(a+2)d\rho(X)v$$ 
	Per $Y$ è tutto analogo.
\end{proof}
Il secondo lemma verrà enunciato durante la dimostrazione del teorema \ref{Theo2}.\\\\
Si dimostra ora il teorema. La strategia di dimostrazione consisterà nel prendere una generica rappresentazione irriducibile e, attraverso considerazioni sugli operatori, giungere a relazioni che la caratterizzino in modo analogo al Teorema \ref{Theo1}.
\begin{proof}[Dimostrazione teorema $\ref{Theo2}$:]
	Sia una rappresentazione irriducibile $d\rho:\mathfrak{sl_2(\mathbb{C})}\rightarrow \mathfrak{gl}(V)$. Sia $u$ un autovettore di $d\rho(H)$ con autovalore $a$. L'esistenza di un autovettore è garantita dal fatto che il campo è complesso. Vogliamo mostrare che $d\rho$ è isomorfa ad una rappresentazione nella forma descritta in precedenza.\\
	Per il Lemma \ref{Lemma1} valgono le relazioni: $$d\rho(H)d\rho(X)u=(a+2)d\rho(X)u$$ e analogamente per applicazioni iterate di $d\rho(X)$
	\begin{equation}
		\label{eq:2.16.1}
		d\rho(H)d\rho(X)^ku=(a+2k)d\rho(X)^ku
		\tag{1}
	\end{equation}
	Dato che $d\rho(H)$ è un operatore su uno spazio vettoriale $V_m$ finito dimensionale, allora non può avere un numero infinito di autovettori. Cioè deve esistere $N\geq 0$ intero, tale che $d\rho(X)^Nu=u_0\neq0$ e $d\rho(X)^{N+1}u=0$.\\
	Si pone $u_0=d\rho(X)^Nu$ e $\lambda=a+2N$ e si sostituisce dentro $(\ref{eq:2.16.1})$, ottenendo: 
	\begin{align*}
		d\rho(H)u_0&=\lambda u_0 & d\rho(X)u_0&=0
	\end{align*} 
	Si pone poi $u_k=d\rho(Y)^ku_0$ con $k$ intero positivo. Per il Lemma 1 si ha $d\rho(H)u_k=(\lambda-2k)u_k$.\\
	Ricordando che $d\rho(H)$ è un operatore su uno spazio vettoriale $V_m$ finito dimensionale, esiste $m\geq0$ intero positivo tale che  $d\rho(Y)^{m+1}=0=u_{m+1}$. Si enuncia ora il seguente lemma:
	\begin{Lem}\label{Lemma2}
		$d\rho(X)u_k=k[\lambda-(k-1)]u_{k-1}$ per $k\geq 1$.
	\end{Lem} 
La dimostrazione sarà data una volta conclusa quella del teorema.\\
\\Se $u_{m+1}=0$ allora $d\rho(X)u_{m+1}=0$. Applicando poi il Lemma \ref{Lemma2} si ottiene $0=(m+1)(\lambda-m)u_m$ da cui segue $\lambda=m$.\\
\\
	Queste considerazioni portano a dire che: per ogni $d\rho $ irriducibile, esistono $m\geq0$ intero e $u_0,...,u_m$ vettori tali che:\begin{itemize}
		\item[(i)] $d\rho(H)u_k=(m-2k)u_k$, ovvero $u_k$ sono autovettori di $d\rho(H)$;
		\item[(ii)] $d\rho(X)u_k=0;$ se k=0 e $d\rho(X)u_k=k(m-(k-1))u_{k-1}$ se $k>0$;
		\item[(iii)] $d\rho(Y)u_k=u_{k+1}$ se $k<m$ e $d\rho(Y)u_k=0$ se $k=m$
	\end{itemize}
I vettori $u_0,...,u_m$ devono essere linearmente indipendenti in quanto sono tutti autovettori di $d\rho(H)$ con autovalori distinti. In più, $span\{u_0,...,u_m\}$ è invariante per costruzione sotto l'azione di $d\rho(H),d\rho(X)$ e $d\rho(Y)$. Dato che $d\rho$ è lineare e $X,Y,H$ generano $\mathfrak{sl_2(\mathbb{C})}$, allora $span\{u_0,...,u_m\}$ è invariante sotto l'azione di un qualsiasi elemento di $\mathfrak{sl_2(\mathbb{C})}$.\\
Ricordando che, per ipotesi, $d\rho:\mathfrak{sl_2(\mathbb{C})}\rightarrow \mathfrak{gl}(V)$ è irriducibile, deve valere\\ $span\{u_0,...,u_m\}\equiv V$. Questo prova che ogni rappresentazione irriducibile di $\mathfrak{sl_2(\mathbb{C})}$ è nella forma $d\rho:\mathfrak{sl_2(\mathbb{C})}\rightarrow \mathfrak{gl}(V_m)$ descritta in precedenza.\\
Al contrario, dato uno spazio vettoriale $V$ di dimensione $m+1$ e fissata una base $\{u_0,...,u_m\}$ di esso, è possibile utilizzare le relazioni $(i),(ii),(iii)$ per definire gli operatori $d\rho(X),d\rho(Y)$ e $d\rho(H)$. Si dimostra che così facendo si ottengono le relazioni di commutazione dell'osservazione $\ref{Obs1}$. Infatti, ricordando che $d\rho$ è un omomorfismo lineare:
$$d\rho([X,Y])u_k=[d\rho(X),d\rho(Y)]u_k=d\rho(X)d\rho(Y)u_k-d\rho(Y)d\rho(X)u_k$$
Supponendo $k\in ]0,m[$ ed utilizzando le relazioni $(i),(ii),(iii)$:
$$d\rho([X,Y])u_k=d\rho(X)u_{k+1}-d\rho(Y)u_{k-1}[k(m-k+1)]=$$
$$=u_k(k+1)(m-k)-u_k[k(m-k+1)]=u_k(m-2k)=d\rho(H)u_k$$
Ovvero $d\rho([X,Y])u_k=d\rho(H)u_k$.\\
Supponendo $k=0$ si ottiene: $$d\rho([X,Y])u_0=d\rho(X)u_{1}-0=$$
$$=u_0(1)(m)=d\rho(H)u_0$$
Infine, supponendo $k=m$:
$$d\rho([X,Y])u_m=0-d\rho(Y)u_{m-1}[m(m-m+1)]=$$
$$=-u_m(m)=u_m(-m)=d\rho(H)u_m$$
Per le altre due relazioni dell'osservazione \ref{Obs1} il procedimento è analogo.\\
Per provare l'irriducibilità della rappresentazione così definita si procede come nel teorema \ref{Theo1}.\\
In conclusione, si è dimostrato che ogni rappresentazione irriducibile di $\mathfrak{sl_2(\mathbb{C})}$ soddisfa le relazioni $(i),(ii),(iii)$. Ciò prova che due qualsiasi tra queste rappresentazioni, di dimensione $m+1$, sono isomorfe.
\end{proof}
Si procede ora alla dimostrazione del Lemma \ref{Lemma2}.
\begin{proof}
	La strategia di dimostrazione sarà quella di utilizzare l'induzione.
	Vogliamo dimostrare che, per $k\geq 1$:
	\begin{equation}
		\label{eq:4}
		d\rho(X)u_k=k[\lambda-(k-1)]u_{k-1} 
\tag{i}
\end{equation}
	Sia allora $k=1$. Sapendo che $d\rho([X,Y])=d\rho(H)=d\rho(X)d\rho(Y)-d\rho(Y)d\rho(X)$ e che $d\rho(Y)u_k=u_{k+1}$, $d\rho(H)u_k=(\lambda-2k)u_k$ e $d\rho(X)u_0=0$, verifichiamo $(i)$ per $k=1$.
	$$d\rho(X)u_1=d\rho(X)d\rho(Y)u_0=d\rho(H)u_0+d\rho(Y)d\rho(X)u_0=$$$$=d\rho(H)u_0+0=(\lambda-0)u_0=\lambda u_0$$
	Dato che la relazione $(i)$ è verificata per $k=1$, supponiamo che lo sia anche per un generico $k$ e dimostriamo che in quel caso è vera anche per $k+1$:
	$$\rho(X)u_{k+1}=d\rho(X)d\rho(Y)u_{k}=d\rho(H)u_k+d\rho(Y)d\rho(X)u_k=$$
	$$=(\lambda-2k)u_k+d\rho(Y)k[\lambda-(k-1)]u_{k-1}=$$ 
	$$=(\lambda-2k)u_k+k[\lambda-(k-1)]u_{k}=(\lambda-2k+k\lambda-k^2+k)u_k=$$
	$$=(\lambda-k)(k+1)u_k$$
	Questo completa la dimostrazione.
\end{proof}
Ritorniamo ora sulle rappresentazioni di $SO_3(\mathbb{R})$. Abbiamo visto che queste ultime coincidono con le rappresentazioni di $SU_2(\mathbb{C})$ che hanno nel nucleo $\pm\mathbb{I}$. E' possibile dimostrare il seguente risultato:
\begin{Prop}
	Le rappresentazioni irriducibili di $SO_3(\mathbb{R})$ hanno dimensione dispari e si ottengono dalle rappresentazioni di $SU_2(\mathbb{C})$ in cui $\pm\mathbb{I}$ agiscono come l'identità.
\end{Prop}
\begin{proof}
	Sia $\rho:SU_2(\mathbb{C})\rightarrow GL(V_m)$ una rappresentazione irriducibile di $SU_2(\mathbb{C})$ come visto nel teorema $\ref{Theo1}$. Se $\rho(\pm\mathbb{I})=id$ allora, come provato nell'osservazione $\ref{Obs:3.5.1}$, è ben definita la rappresentazione irriducibile $\rho':SU_2(\mathbb{C})/\pm\mathbb{I}\rightarrow GL(V_m)$ tale che $\rho'(\pm a)=\rho(a)$, con $a\in SU_2(\mathbb{C})$. Sfruttando l'isomorfismo $T':SU_2(\mathbb{C})/\pm\mathbb{I}\rightarrow SO_3(\mathbb{R})$ trovato nella proposizione $\ref{prop:3.5.1}$, possiamo definire una rappresentazione $\xi=\rho'\circ T'^{-1}$ di $SO_3(\mathbb{R})$, ovvero $\xi:SO_3(\mathbb{R})\rightarrow GL(V_m)$.
	Inoltre, esplicitando l'azione dell'identità su di un generico elemento di $GL(V_m)$ si ottiene: $$\rho(-\mathbb{I})f(x,y)=f(-x,-y)=\sum_{i=0}^{m}a_m(-x)^{m-i}(-y)^i=\sum_{i=0}^{m}(-1)^ma_mx^{m-i}y^i$$
	Ma, per costruzione, $\rho(\mathbb{I})=\rho(-\mathbb{I})$, da cui:
	$$(-1)^m=1$$
	che è verificato solamente se $m$ è pari.
\end{proof}
\chapter{Quantizzazione del momento angolare}
In questo capitolo utilizzeremo i risultati trovati in precedenza per discutere la quantizzazione del momento angolare in meccanica quantistica. Vedremo come, attraverso una stretta corrispondenza tra operatori di rotazione e matrici appartenenti ad $SO_3(\mathbb{R})$, sia possibile determinare alcune proprietà importanti degli operatori di momento angolare in meccanica quantistica.
\section{Operatore momento angolare}
In questa sezione introdurremo il concetto di operatore di momento angolare. Per approfondimenti su questo tema consultare [7], cap. 7 e [9] cap. 6. \\
\\
Una particella quantistica è descritta da una funzione d'onda $\psi$ la cui evoluzione temporale è governata dall'equazione di Schrödinger. Nel formalismo di Dirac, una generica funzione d'onda $\psi$, appartenente allo spazio $\mathcal{H'}$ di Hilbert delle funzioni complesse nello spazio delle configurazioni, si rappresenta con la notazione $|\psi\rangle$. Introduciamo ora il concetto di operatore di momento angolare. In generale, un operatore è un elemento dello spazio $End(\mathcal{H'})$. Dati 3 operatori, è possibile definire, per semplicità di notazione, un operatore vettoriale come $\hat{\textbf{A}}=(\hat{A_1},\hat{A_2},\hat{A_3})$ le cui componenti sono operatori. Formalmente un operatore vettoriale è quindi un elemento di $End(\mathcal{H'})\times End(\mathcal{H'})\times End(\mathcal{H'})$.
\begin{Def}
	Un operatore vettoriale $\hat{\textbf{j}}$ è definito di \textit{momento angolare} se le sue componenti rispettano le relazioni di commutazione $[\hat{j_i},\hat{j_j}]=i\hbar\sum_{k=1}^{3}\epsilon_{ijk}\hat{j_k}$ e la condizione $\hat{j}_i=\hat{j}^+_i$, dove il prodotto $[,]$ tra due operatori è definito come $[\hat{j_i},\hat{j_j}]=\hat{j_i}\hat{j_j}-\hat{j_j}\hat{j_i}$.
\end{Def} 
\begin{Obs}
La condizione $\hat{j}_i=\hat{j}^+_i$ è la richiesta che l'operatore si autoaggiunto ed è motivata dal fatto che esso deve rappresentare un osservabile. Ricordiamo che in fisica quantistica vi è una corrispondenza biunivoca tra osservabili ed operatori autoaggiunti e che due osservabili sono simultaneamente definiti solamente se i relativi operatori commutano tra di loro. Questo implica l'impossibilità di ottenere simultaneamente due valori per le componenti del momento angolare, in quanto gli operatori $\hat{j}_i$ non commutano tra loro. Tuttavia, a partire dalle componenti di $\hat{\textbf{j}}$, è possibile costruire un ulteriore operatore.
\end{Obs}
\begin{Def}
	Si definisce l'operatore \textit{modulo quadro} di $\hat{j}^2=\hat{\textbf{j}}^2$ come $\hat{\textbf{j}}^2=\sum_{k=0}^{3}\hat{j_k}^2$.
\end{Def}
E' possibile mostrare che questo operatore, oltre ad essere autoaggiunto, è tale che
$$[\hat{j}^2,\hat{j_i}]=0$$
Ciò implica la possibilità di ottenere valori simultaneamente definiti degli osservabili associati a $\hat{j}^2$ ed a $\hat{j_z}$, una generica componente del momento angolare.
Per approfondire questo risultato si veda [9] pag. 670 cap 6.
\section{Momento angolare e rotazioni}
In questa sezione studiamo la corrispondenza tra operatori di rotazione e matrici di $SO_3(\mathbb{R})$.\\
\\
Consideriamo ora il gruppo $SO_3(\mathbb{R})$ delle matrici che agiscono come rotazioni sui vettori  $\vec{x}$ dello spazio delle configurazioni $\mathbb{R}^3$. Come precedentemente visto, l'algebra di Lie di questo gruppo è
$$\mathfrak{so_3}(\mathbb{R})=\{A\in M_{3\times 3}(\mathbb{R})|\, tr(A)=0,\, A^T=-A\}$$
Tra le possibili basi di questo spazio vettoriale consideriamo $\{J_1,J_2,J_3\}$, dove:
$$
J_1=
\begin{pmatrix}
	0 &0&0\\
	0 &0&-1\\
	0 &1&0
\end{pmatrix} \, ;
J_2=
\begin{pmatrix}
	0 &0&1\\
	0 &0&0\\
	-1 &0&0
\end{pmatrix} \, ;
J_3=
\begin{pmatrix}
	0 &-1&0\\
	1 &0&0\\
	0 &0&0
\end{pmatrix} \, ;
$$
E' possibile dimostrare che queste matrici soddisfano le relazioni di commutazione:
$$[J_i,J_j]=\sum_{k}\epsilon_{ijk}J_k$$
dove $\epsilon_{ijk}$ è il simbolo di Levi Civita in 3 dimensioni: 
\begin{equation}
	\begin{cases}
		\epsilon_{ijk}=+1$ per permutazioni pari di $(i,j,k)\\
		\epsilon_{ijk}=-1 $ per permutazioni dispari di $(i,j,k)\\
		\epsilon_{ijk}=0$ se due simboli sono uguali$
	\end{cases}
\end{equation}
In più, $J_i$ sono per definizione antisimmetriche.
Vediamo che queste matrici rispettano le stesse relazioni di commutazione degli operatori di momento angolare viste nella sezione precedente, a meno di una costante. Di seguito è riportato brevemente il calcolo per una bracket, per le rimanenti il procedimento è analogo.
$$[J_1,J_2]=\bigg[
\begin{pmatrix}
	0 &0&0\\
	0 &0&-1\\
	0 &1&0
\end{pmatrix}
\begin{pmatrix}
	0 &0&1\\
	0 &0&0\\
	-1 &0&0
\end{pmatrix}
-
\begin{pmatrix}
	0 &0&1\\
	0 &0&0\\
	-1 &0&0
\end{pmatrix}
\begin{pmatrix}
	0 &0&0\\
	0 &0&-1\\
	0 &1&0
\end{pmatrix}
\bigg]=$$
$$
\begin{pmatrix}
	0 &-1&0\\
	1 &0&0\\
	0 &0&0
\end{pmatrix}= J_3$$
Consideriamo ora una particella individuata da una funzione d'onda $|\psi\rangle$. Quest'ultima avrà come possibili rappresentativi $\langle \vec{x}|\psi\rangle=\psi(\vec{x})$ dove ricordiamo che $\vec{x}$ è un vettore dello spazio delle configurazioni.
\begin{Def}
	Sia una matrice di rotazione $R\in SO_3(\mathbb{R})$. Definiamo l'operatore di rotazione $\hat{R}$ come l'operatore tale per cui:
	$\hat{R}|\psi\rangle=|\psi'\rangle$ con $\psi(\vec{x})=\psi'(R\vec{x})$.
\end{Def}
Data la corrispondenza costruita tra operatori $\hat{R}$ e matrici $R$, possiamo studiare le rappresentazioni dell'insieme degli operatori $\hat{R}$ attraverso quelle di $SO_3(\mathbb{R})$. E' inoltre possibile dimostrare che un operatore $\hat{R}$, associato ad una matrice $R$ di rotazione attorno ad un asse $\vec{v}$ di un angolo $\theta$, può essere scritto come 
$$\hat{R}=exp(-i\hbar^{-1}\theta\vec{v}\cdot\hat{\textbf{j}})$$
dove $\hat{\textbf{j}}$ è un operatore vettoriale di momento angolare. In questo senso, gli operatori di rotazione sono generati dagli operatori di momento angolare. Per la dimostrazione si veda [7] pag 200, cap. 7.
Si può verificare che esiste una corrispondenza anche tra operatori di momento angolare che generano $\hat{R}$ e matrici $J_i$ appartenenti all'algebra di Lie di $SO_3(\mathbb{R})$. Infatti, la formula di rotazione di Rodrigues ci permette di scrivere:
$$R=e^{\theta J}=e^{-i\hbar^{-1}\theta i\hbar J}$$
dove $J\in \mathfrak{so_3}(\mathbb{R})$ e $R$ è una rotazione di angolo $\theta$ attorno ad un asse. Per maggiori informazioni su questa formula si veda [8]. Quindi, presa $J$ nell'algebra di Lie di $SO_3(\mathbb{R})$, possiamo associare ad ogni matrice $i\hbar J$ un operatore $\vec{v}\cdot\hat{\textbf{j}}$.\\
\\  
\begin{comment}
E' noto, per il teorema delle rotazioni di Eulero, che ogni rotazione nello spazio tridimensionale lascia un asse fisso, passante per il centro di rotazione. Inoltre, vale la seguente relazione:
$$R_z(\theta)=\begin{pmatrix}
cos(\theta)&-sin(\theta)&0\\
sin(\theta)&cos(\theta)&0\\
0&0&1
\end{pmatrix}=e^{\theta J_3}$$
L'operatore associato a questa matrice è $\hat{R_z(\theta)}=exp(-i\hbar^{-1}\theta \hat{j_z})$ dove $\hat{j_z}$ è un operatore di momento angolare.
Possiamo allora generalizzare attraverso la formula di Rodrigues e scrivere, per una generica rotazione: 
\end{comment}
	Vogliamo studiare le rappresentazioni degli operatori di momento angolare attraverso quelle dell'algebra $\mathfrak{so_3}(\mathbb{R})$, generata dai $J_i$. Ricordiamo che, poiché l'insieme $SO_3(\mathbb{R})$ non è semplicemente connesso, non vi è una corrispondenza biunivoca tra le sue rappresentazioni e quelle della sua algebra $\mathfrak{so_3}(\mathbb{R})$. Tuttavia tali rappresentazioni sono completamente classificate, come visto nel capitolo \ref{chap:3}, osservazione \ref{Obs:3.5.1}.
\section{Le rappresentazioni del momento angolare}
In questa sezione utilizzeremo i risultati precedenti per determinare le rappresentazioni degli operatori di momento angolare.\\
\\
Nel capitolo \ref{chap:3} abbiamo provato che le rappresentazioni di $SO_3(\mathbb{R})$ si ricavano dalle rappresentazioni di $SU_2(\mathbb{C})$ dove $\pm\mathbb{I}$ agisce come l'identità.
Consideriamo dunque il gruppo $SU_2(\mathbb{C})=\{A\in M_{n\times n}|AA^{+}=I=A^{+}A;det(A)=1\}$ la cui algebra di Lie è $$\mathfrak{su_2(\mathbb{C})}=\{X|X\in M_{n\times n} ;X^{+}=-X;tr(X)=0\}$$
Una base per lo spazio $\mathfrak{su_2(\mathbb{C})}$ è costituita dalle matrici di Pauli
$$
\sigma_1={1\over2}\begin{pmatrix}
	0 &i\\
	i &0\\
\end{pmatrix}\,;\,
\sigma_2={1\over2}\begin{pmatrix}
	0 &-1\\
	1 &0\\
\end{pmatrix}\,;\,
\sigma_3={1\over2}\begin{pmatrix}
	i &0\\
	0 &-i\\
\end{pmatrix}
$$
Anche per queste matrici non è complicato dimostrare che valgono le regole di commutazione:
$$[\sigma_i,\sigma_j]=\sum_{k=1}^{3}\epsilon_{ijk}\sigma_k$$ 
dove $\epsilon_{ijk}$ è il simbolo di Levi Civita. Le dimostrazioni sono analoghe al caso discusso nella sezione precedente.
\begin{Prop} \label{Prop:4.3.1}
	Le algebre di lie $\mathfrak{su_2(\mathbb{C})}$ e $\mathfrak{so_3}(\mathbb{R})$ sono isomorfe.
\end{Prop}
\begin{proof}
	Consideriamo le base $\{\sigma_1,\sigma_2,\sigma_3\}$ di $\mathfrak{su_2(\mathbb{C})}$ e $\{J_1,J_2,J_3\}$ di $\mathfrak{so_3}(\mathbb{R})$ vista nella sezione precedente. Ricordando che un isomorfismo associa basi a basi, consideriamo la mappa
	$\sigma_i\rightarrow J_i$ per $i=1,2,3$. Dato che le matrici $\sigma_i$ e $J_i$ rispettano le stesse regole di commutazione, la mappa costruita è isomorfismo.
\end{proof}
\begin{Obs}
	La proposizione \ref{Prop:4.3.1} ci permette di studiare le azioni degli operatori $\hat{j}$ attraverso quelle di $\mathfrak{su_2(\mathbb{C})}$. Più precisamente, attraverso quelle della complessificazione $\mathfrak{su_2(\mathbb{C})_c}$. Se consideriamo come base di $\mathfrak{su_2(\mathbb{C})_c}$ le matrici $i\hbar\sigma_i$, allora queste rispettano le stesse regole di commutazione degli operatori di momento angolare:
	$$[i\hbar\sigma_i,i\hbar\sigma_j]=i\hbar\sum_{k=1}^{3}i\hbar\epsilon_{ijk}\sigma_k$$ 
\end{Obs}
Come dimostrato nel capitolo \ref{chap:3}, teorema \ref{Theo2}, una qualsiasi rappresentazione irriducibile finito dimensionale $d\rho$ di $\mathfrak{su_2(\mathbb{C})_c}$ è del tipo $d\rho: \mathfrak{su_2(\mathbb{C})_c}\rightarrow End(V_m)$, dove $dim(V)=m+1$. Inoltre, fissata la base $\{H,\, X,\, Y\}$ di $\mathfrak{su_2(\mathbb{C})_c}$, esistono $u_0,...,u_m$ vettori di base per $V_m$ tali che
\begin{itemize}
	\item[(i)] $d\rho(H)u_k=(m-2k)u_k$, ovvero $u_k$ sono autovettori di $d\rho(H)$;
	\item[(ii)] $d\rho(X)u_k=0;$ se k=0 e $d\rho(X)u_k=k(m-(k-1))u_{k-1}$ se $k>0$;
	\item[(iii)] $d\rho(Y)u_k=u_{k+1}$ se $k<m$ e $d\rho(Y)u_k=0$ se $k=m$
\end{itemize}
\begin{Obs}
	Osserviamo innanzitutto che $\sigma_1={i\over 2}(X+Y)$; $\sigma_2={i\over 2}(Y-X)$; $\sigma_3={i\over 2}(H)$. Per linearità di $d\rho$ allora possiamo scrivere: $$d\rho(i\hbar\sigma_1)=i\hbar d\rho({i\over 2}(X+Y))=i\hbar({i\over2})(d\rho(X)+d\rho(Y))$$
	$$d\rho(i\hbar\sigma_2)=i\hbar d\rho({1\over 2}(Y-X))=i\hbar({1\over2})(d\rho(Y)-d\rho(X))$$
	$$d\rho(i\hbar\sigma_3)=i\hbar d\rho({i\over 2}H)=i\hbar({i\over2})d\rho(H)$$
	Ciò ci permette di calcolare l'azione di $i\hbar\sigma_i$ sui vettori di base di $V$. Tuttavia, ricordiamo che queste matrici sono in corrispondenza con gli operatori di momento angolare: dato che gli unici osservabili simultaneamente definiti sono $j_z=j_3$ e $j^2$, occorre trovare un'espressione per l'azione di $\sigma^2=-\hbar^2(\sigma_1^2+\sigma_2^2+\sigma_3^2)$. Attraverso un rapido calcolo notiamo che:
	$$\sigma^2=\hbar^2[{(X+Y)^2\over 4}-{(Y-X)^2\over 4}+{H^2\over 4}]=$$
	$$=\hbar^2[{(2XY+2YX+H^2)\over 4}]=\hbar^2{3\over 4}\mathbb{I}$$
	e l'identità non appartiene all'algebra $\mathfrak{su_2(\mathbb{C})_c}$. Ovvero l'azione di $\sigma^2$ non è definita dalla mappa $d\rho$. 
\end{Obs}
Per risolvere questo problema utilizziamo l'elemento di Casimir, che nel caso dell'algebra di Lie coincide con $\sigma^2$. Lo studio di questo elemento va al di là degli argomenti trattati da questa tesi. Per maggiori informazioni su questo argomento si veda [4] cap. 9 e 10 parte 2, o ancora [2] cap. 2 pag 55 e cap. 3 pag. 216. Per i nostri scopi è sufficiente sapere che, data una rappresentazione $d\rho$ di $\mathfrak{su_2(\mathbb{C})_c}$ come sopra, il dominio di questa è estendibile ad un insieme contenente $\mathfrak{su_2(\mathbb{C})_c}$ e $\sigma^2$ in modo che
$$d\rho(\sigma^2)=c\cdot id$$ 
dove $id$ è l'operatore identità e $c$ è un coefficiente che assume il valore di ${\hbar^2\over 4}(m^2+2m)$. Per la dimostrazione di questo risultato si veda [4] pag. 288 cap. 10.\\
Dunque, attraverso l'elemento di Casimir e le relazioni $(i),(ii),(iii)$, possiamo scrivere:
	\begin{itemize}
		\centering
		\item $d\rho(i\hbar\sigma_3)u_k=-{\hbar\over 2}(m-2k)u_k$;
		\item $d\rho(\sigma^2)u_k=\hbar^2{m(m+2)\over 4}u_k$;
	\end{itemize}
Operando poi un cambio di variabile: $l={m\over2}$ otteniamo:
\begin{itemize}
	\centering
	\item $d\rho(i\hbar\sigma_3)u_k=-\hbar(l-k)u_k$;
	\item $d\rho(\sigma^2)u_k=\hbar^2l(l+1)u_k$;
\end{itemize}
Quindi gli autovalori di $d\rho(i\hbar\sigma_3)$ e $d\rho(\sigma^2)$ sono base per $V_m$ e sono indicizzati da due numeri, detti \textit{quantici}, $l$ ed $m_l=-(l-k)$. In particolare, $l$ è necessariamente positivo in quanto $2l$ è la dimensione di $V_m$; $m_l$ invece può variare da $0-l=-l$ ad $m-l=l$.
\begin{Obs}
	Data la corrispondenza tra operatori di momento angolare $\hat{j}$ e matrici $J$ appartenenti all'algebra di Lie di $SO_3(\mathbb{R})$, le rappresentazioni degli operatori $\hat{j}$ non sono altro che quelle dell'algebra di $SO_3(\mathbb{R})$, che è isomorfa ad $\mathfrak{su_2(\mathbb{C})_c}$.
	Possiamo allora enunciare la seguente proposizione:
\end{Obs}
\begin{Prop}
	Sia $\hat{\textbf{j}}$ un vettore operatoriale di momento angolare e $j^2$ l'operatore modulo quadro associato. Gli autoket di questi operatori sono indicizzati da due numeri quantici: $l\geq0$ e $m=-l,-l+1,...,l-1,l$. Le azioni degli operatori $\hat{j_z}$ e $\hat{j}^2$ su di uno spazio vettoriale a dimensione finita $V\subset \mathcal{H'}$ sono:
	$$\hat{j}^2|l,m_l\rangle=|l,m_l\rangle l(l+1)\hbar^2$$ 
	$$\hat{j_z}|l,m_l\rangle=|l,m_l\rangle m_l\hbar$$
\end{Prop}
\chapter*{Bibliografia}
\begin{itemize}
	\item[$\circ$] [1] Loring W.Tu, An Introduction to Manifolds, Springer, 2011
	\item[$\circ$] [2] V. S. Varadarajan, Lie Groups, Lie Algebras, and Their Representations, Springer,
	1984.
	\item[$\circ$] [3] Theodor Bröcker , Tammo Dieck, Representations of Compact Lie Groups, Springer, 1985
	\item[$\circ$] [4] Brian C. Hall, Lie Groups, Lie Algebras, and Representations, Springer, 2015
	\item [$\circ$] [5] Czes Kosniowski, A First Course in Algebraic Topology, Cambridge, Cambridge University Press, 1980
	\item [$\circ$] [6] C. Procesi, Aspetti geometrici e combinatori della teoria delle rappresentazioni del gruppo unitario, Pitagora Editrice, 1991
	\item [$\circ$] [7] Leonard Isaac Schiff,
	Quantum Mechanics, Third Edition, McGraw-Hill Education, 1968
	\item [$\circ$] [8] Kuo Kan Liang, Efficient conversion from rotating matrix to rotation axis and angle by extending Rodrigues' formula, 2018\\
	https://arxiv.org/pdf/1810.02999.pdf
	\item [$\circ$] [9]  Claude Cohen-Tannoudji, Bernard Diu, Frank Laloe, Quantum Mechanics, Vol. 1, Wiley, 1991
\end{itemize}
\addcontentsline{toc}{chapter}{Bibliografia}
\end{document}
